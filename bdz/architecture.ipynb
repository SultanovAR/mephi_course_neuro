{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.050634</td>\n",
       "      <td>0.027240</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>-0.032899</td>\n",
       "      <td>0.038020</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>-0.014699</td>\n",
       "      <td>-0.013311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.005257</td>\n",
       "      <td>-0.006020</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.010556</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.082828</td>\n",
       "      <td>0.112354</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>-0.003085</td>\n",
       "      <td>-0.008792</td>\n",
       "      <td>-0.051937</td>\n",
       "      <td>0.034442</td>\n",
       "      <td>0.018615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021127</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-0.006346</td>\n",
       "      <td>-0.005416</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042588</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>-0.049124</td>\n",
       "      <td>-0.006528</td>\n",
       "      <td>-0.016737</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.066970</td>\n",
       "      <td>-0.001077</td>\n",
       "      <td>0.058637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>-0.002685</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>-0.007280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.042608</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>-0.049140</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>-0.016723</td>\n",
       "      <td>-0.026691</td>\n",
       "      <td>-0.066956</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>0.058653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005121</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.001166</td>\n",
       "      <td>-0.007277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005453</td>\n",
       "      <td>-0.084841</td>\n",
       "      <td>-0.021381</td>\n",
       "      <td>-0.010569</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>-0.043900</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>-0.095431</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005556</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>-0.010629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.050634  0.027240 -0.022914  0.037219  0.018378 -0.032899  0.038020   \n",
       "1 -0.082828  0.112354  0.009881  0.012665  0.008541 -0.003085 -0.008792   \n",
       "2 -0.042588  0.001930  0.008672 -0.049124 -0.006528 -0.016737 -0.026704   \n",
       "3 -0.042608  0.001906  0.008685 -0.049140 -0.006525 -0.016723 -0.026691   \n",
       "4 -0.005453 -0.084841 -0.021381 -0.010569  0.012817  0.006240 -0.043900   \n",
       "\n",
       "         7         8         9  ...        41        42        43        44  \\\n",
       "0  0.007106 -0.014699 -0.013311 ... -0.004743  0.000467 -0.005257 -0.006020   \n",
       "1 -0.051937  0.034442  0.018615 ... -0.021127  0.002920  0.002466 -0.006346   \n",
       "2 -0.066970 -0.001077  0.058637 ... -0.005165 -0.002685  0.001238 -0.000939   \n",
       "3 -0.066956 -0.001069  0.058653 ... -0.005121 -0.002631  0.001206 -0.001003   \n",
       "4  0.008502 -0.095431 -0.005969 ... -0.005556 -0.000033 -0.000223 -0.010339   \n",
       "\n",
       "         45        46        47        48        49  50  \n",
       "0 -0.005111 -0.010556 -0.002886 -0.004013 -0.002646   1  \n",
       "1 -0.005416  0.005263  0.001795 -0.001875 -0.005464   1  \n",
       "2 -0.002155  0.004361 -0.000085 -0.001146 -0.007280   1  \n",
       "3 -0.002150  0.004290 -0.000087 -0.001166 -0.007277   1  \n",
       "4  0.001835 -0.001127 -0.004829  0.001877 -0.010629   1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(filepath_or_buffer='pretreatmented_data.csv', header=None)\n",
    "FEATURES_INDEX = np.arange(50)\n",
    "LABELS_INDEX = 50\n",
    "BATCH_SIZE = 50\n",
    "LOSS_THRESHOLD = 1e-7\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>-0.023177</td>\n",
       "      <td>-0.034199</td>\n",
       "      <td>-0.071174</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>-0.055537</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.085029</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.022024</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.003055</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.005397</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.004931</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>-0.068698</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>-0.120875</td>\n",
       "      <td>-0.031199</td>\n",
       "      <td>-0.126144</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.027971</td>\n",
       "      <td>0.042212</td>\n",
       "      <td>-0.037903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.001545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>-0.022014</td>\n",
       "      <td>-0.018537</td>\n",
       "      <td>-0.052204</td>\n",
       "      <td>-0.010769</td>\n",
       "      <td>-0.049487</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>-0.026063</td>\n",
       "      <td>-0.004448</td>\n",
       "      <td>-0.008374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015350</td>\n",
       "      <td>-0.018111</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>-0.003928</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>-0.027492</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.047973</td>\n",
       "      <td>-0.013806</td>\n",
       "      <td>-0.009351</td>\n",
       "      <td>-0.009311</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>-0.013044</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>-0.005193</td>\n",
       "      <td>-0.005427</td>\n",
       "      <td>-0.004483</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>-0.053112</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.010851</td>\n",
       "      <td>-0.040524</td>\n",
       "      <td>-0.143514</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>-0.028555</td>\n",
       "      <td>0.030408</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "2708 -0.023177 -0.034199 -0.071174  0.034209 -0.055537  0.050054  0.085029   \n",
       "2709 -0.068698  0.057827  0.062494 -0.120875 -0.031199 -0.126144 -0.001503   \n",
       "2710 -0.022014 -0.018537 -0.052204 -0.010769 -0.049487  0.042335  0.060547   \n",
       "2711 -0.027492 -0.037501 -0.001082 -0.047973 -0.013806 -0.009351 -0.009311   \n",
       "2712 -0.053112  0.017851 -0.001592 -0.010851 -0.040524 -0.143514  0.026496   \n",
       "\n",
       "            7         8         9  ...        41        42        43  \\\n",
       "2708 -0.002683 -0.022024  0.001740 ... -0.000197 -0.003055  0.006381   \n",
       "2709 -0.027971  0.042212 -0.037903 ...  0.007117 -0.001194 -0.000628   \n",
       "2710 -0.026063 -0.004448 -0.008374 ... -0.015350 -0.018111  0.004594   \n",
       "2711 -0.024605 -0.013044  0.041648 ...  0.009767  0.000280  0.005480   \n",
       "2712 -0.028555  0.030408  0.003770 ... -0.005770  0.001425 -0.000558   \n",
       "\n",
       "            44        45        46        47        48        49  50  \n",
       "2708 -0.000235 -0.005397 -0.003612 -0.000170 -0.004931  0.000354   0  \n",
       "2709 -0.002963  0.001091  0.002984  0.002117 -0.000214 -0.001545   0  \n",
       "2710  0.017790 -0.003928  0.013328  0.001513  0.000267  0.002323   0  \n",
       "2711 -0.005193 -0.005427 -0.004483 -0.003516 -0.003058  0.003073   0  \n",
       "2712 -0.001323 -0.000568  0.003484 -0.000813 -0.002720  0.002752   0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dataset = dataset[dataset[LABELS_INDEX] == 1]\n",
    "nonspam_dataset = dataset[dataset[LABELS_INDEX] == 0]\n",
    "nonspam_dataset.reset_index(drop=True, inplace=True)\n",
    "spam_dataset.reset_index(drop=True, inplace=True)\n",
    "nonspam_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621 1311 438 4370 4370\n"
     ]
    }
   ],
   "source": [
    "rand_indxs_spam = np.arange(len(spam_dataset))\n",
    "rand_indxs_nonspam = np.arange(len(nonspam_dataset))\n",
    "np.random.shuffle(rand_indxs_nonspam)\n",
    "np.random.shuffle(rand_indxs_spam)\n",
    "\n",
    "spam_f_threshold = int(len(spam_dataset)*0.6)\n",
    "spam_s_threshold = int(len(spam_dataset)*0.9)\n",
    "\n",
    "nonspam_f_threshold = int(len(nonspam_dataset)*0.6)\n",
    "nonspam_s_threshold = int(len(nonspam_dataset)*0.9)\n",
    "\n",
    "learn_dataset = pd.concat([spam_dataset.iloc[rand_indxs_spam[:spam_f_threshold]],\n",
    "                          nonspam_dataset.iloc[rand_indxs_nonspam[:nonspam_f_threshold]]])\n",
    "\n",
    "valid_dataset = pd.concat([spam_dataset.iloc[rand_indxs_spam[spam_f_threshold:spam_s_threshold]],\n",
    "                          nonspam_dataset.iloc[rand_indxs_nonspam[nonspam_f_threshold:nonspam_s_threshold]]])\n",
    "\n",
    "test_dataset = pd.concat([spam_dataset.iloc[rand_indxs_spam[spam_s_threshold:]],\n",
    "                         nonspam_dataset.iloc[rand_indxs_nonspam[nonspam_s_threshold:]]])\n",
    "\n",
    "print(len(learn_dataset), len(valid_dataset), len(test_dataset), len(learn_dataset)+len(valid_dataset)+len(test_dataset), len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dataset = np.array(learn_dataset)\n",
    "valid_dataset = np.array(valid_dataset)\n",
    "test_dataset = np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dataloader = DataLoader(learn_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_layer_in_nets = [(20, 10, 10), (25, 15, 10), (20, 20, 20), (20, 30, 10), (30, 30, 30), (30, 40, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, amount_layer_in_nets[0][0])\n",
    "        self.lin2 = nn.Linear(amount_layer_in_nets[0][0], amount_layer_in_nets[0][1])\n",
    "        self.lin3 = nn.Linear(amount_layer_in_nets[0][1], amount_layer_in_nets[0][2])\n",
    "        self.lin4 = nn.Linear(amount_layer_in_nets[0][2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, amount_layer_in_nets[1][0])\n",
    "        self.lin2 = nn.Linear(amount_layer_in_nets[1][0], amount_layer_in_nets[1][1])\n",
    "        self.lin3 = nn.Linear(amount_layer_in_nets[1][1], amount_layer_in_nets[1][2])\n",
    "        self.lin4 = nn.Linear(amount_layer_in_nets[1][2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, amount_layer_in_nets[2][0])\n",
    "        self.lin2 = nn.Linear(amount_layer_in_nets[2][0], amount_layer_in_nets[2][1])\n",
    "        self.lin3 = nn.Linear(amount_layer_in_nets[2][1], amount_layer_in_nets[2][2])\n",
    "        self.lin4 = nn.Linear(amount_layer_in_nets[2][2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model4, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, amount_layer_in_nets[3][0])\n",
    "        self.lin2 = nn.Linear(amount_layer_in_nets[3][0], amount_layer_in_nets[3][1])\n",
    "        self.lin3 = nn.Linear(amount_layer_in_nets[3][1], amount_layer_in_nets[3][2])\n",
    "        self.lin4 = nn.Linear(amount_layer_in_nets[3][2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model5, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, amount_layer_in_nets[4][0])\n",
    "        self.lin2 = nn.Linear(amount_layer_in_nets[4][0], amount_layer_in_nets[4][1])\n",
    "        self.lin3 = nn.Linear(amount_layer_in_nets[4][1], amount_layer_in_nets[4][2])\n",
    "        self.lin4 = nn.Linear(amount_layer_in_nets[4][2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model6, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, amount_layer_in_nets[5][0])\n",
    "        self.lin2 = nn.Linear(amount_layer_in_nets[5][0], amount_layer_in_nets[5][1])\n",
    "        self.lin3 = nn.Linear(amount_layer_in_nets[5][1], amount_layer_in_nets[5][2])\n",
    "        self.lin4 = nn.Linear(amount_layer_in_nets[5][2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = Model1()\n",
    "net_2 = Model2()\n",
    "net_3 = Model3()\n",
    "net_4 = Model4()\n",
    "net_5 = Model5()\n",
    "net_6 = Model6()\n",
    "\n",
    "list_of_nets = [net_1, net_2, net_3, net_4, net_5, net_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is_load = False\n",
    "#if is_load:\n",
    "#    net.load_state_dict(torch.load('gd/net_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализация весов\n",
    "null_weigth_of_nets = []\n",
    "sd = []\n",
    "null_weigth = []\n",
    "\n",
    "def get_weights(layer):\n",
    "        if (type(layer) == nn.Linear):\n",
    "            cur_std = sd.pop()\n",
    "            null_weigth.append(torch.randn(layer.weight.data.shape)*cur_std)\n",
    "            null_weigth.append(torch.randn(layer.bias.data.shape)*cur_std)\n",
    "\n",
    "for index, net in enumerate(list_of_nets):\n",
    "    sd = [(2/(50+amount_layer_in_nets[index][0]+1))**(1/2),\\\n",
    "          (2/(amount_layer_in_nets[index][0]+amount_layer_in_nets[index][1]+1))**(1/2),\\\n",
    "          (32/(amount_layer_in_nets[index][1]+amount_layer_in_nets[index][2]+1))**(1/2),\\\n",
    "          (32/(amount_layer_in_nets[index][2]+1+1))**(1/2)]\n",
    "    sd.reverse()\n",
    "    null_weigth = []\n",
    "\n",
    "    net.apply(get_weights)\n",
    "    null_weigth.reverse()\n",
    "    null_weigth_of_nets.append(null_weigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 50])\n",
      "\n",
      "\n",
      "torch.Size([1])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 15])\n",
      "torch.Size([15])\n",
      "torch.Size([15, 25])\n",
      "torch.Size([25])\n",
      "torch.Size([25, 50])\n",
      "\n",
      "\n",
      "torch.Size([1])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 50])\n",
      "\n",
      "\n",
      "torch.Size([1])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 50])\n",
      "\n",
      "\n",
      "torch.Size([1])\n",
      "torch.Size([1, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 50])\n",
      "\n",
      "\n",
      "torch.Size([1])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 40])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 50])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for null_w in null_weigth_of_nets:\n",
    "    for k in null_w:\n",
    "        print(k.shape)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weigths(layer):\n",
    "    if(type(layer) == nn.Linear):\n",
    "        layer.weight.data = (tmp_null_weigth.pop()).clone()\n",
    "        layer.bias.data = (tmp_null_weigth.pop()).clone()\n",
    "\n",
    "for index, net in enumerate(list_of_nets):\n",
    "    tmp_null_weigth = list(null_weigth_of_nets[index])\n",
    "    net.apply(init_weigths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "torch.Size([25, 50])\n",
      "torch.Size([25])\n",
      "torch.Size([15, 25])\n",
      "torch.Size([15])\n",
      "torch.Size([10, 15])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "torch.Size([20, 50])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "torch.Size([20, 50])\n",
      "torch.Size([20])\n",
      "torch.Size([30, 20])\n",
      "torch.Size([30])\n",
      "torch.Size([10, 30])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "torch.Size([30, 50])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "torch.Size([30, 50])\n",
      "torch.Size([30])\n",
      "torch.Size([40, 30])\n",
      "torch.Size([40])\n",
      "torch.Size([20, 40])\n",
      "torch.Size([20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for net in list_of_nets:\n",
    "    for layer in net.parameters():\n",
    "        print(layer.shape)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(size_average=True)\n",
    "optimizer = optim.LBFGS(net_1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1(\n",
      "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (lin4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1311])) that is different to the input size (torch.Size([1311, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.996927647331177e-09\n",
      "net:  Model1(\n",
      "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (lin4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")  \n",
      " breaked on epoch:  233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_loss = []\n",
    "valid_loss = []\n",
    "test_loss = []\n",
    "epoch_list = []\n",
    "\n",
    "print(net_1)\n",
    "for epoch in range(1000):\n",
    "    loss_acc = []\n",
    "    for learn_data in learn_dataloader:\n",
    "        features, labels = learn_data[:, FEATURES_INDEX].float(), learn_data[:, LABELS_INDEX].float()\n",
    "        features.requres_grad = True\n",
    "        labels.requres_grad = True\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net_1(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        loss = optimizer.step(closure)\n",
    "        loss_acc.append(float(loss))\n",
    "    learn_loss.append(np.mean(loss_acc))\n",
    "\n",
    "    #критерий останова\n",
    "    if (epoch > 100) and\\\n",
    "    (abs(learn_loss[-1] - learn_loss[-2]) < 1e-8):\n",
    "        print(learn_loss[-1] - learn_loss[-2])\n",
    "        print('net: ', net_1, ' \\n breaked on epoch: ', epoch, '\\n')\n",
    "        break\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        epoch_list.append(epoch)\n",
    "        for valid_data in valid_dataloader:\n",
    "            features, labels = valid_data[:, FEATURES_INDEX].float(), valid_data[:, LABELS_INDEX].float()\n",
    "            outputs = net_1(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss.append(float(loss))\n",
    "\n",
    "        for test_data in valid_dataloader:\n",
    "            features, labels = test_data[:, FEATURES_INDEX].float(), test_data[:, LABELS_INDEX].float()\n",
    "            outputs = net_1(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss.append(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1091f8c50>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c9ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn_loss_by_nets = []\n",
    "valid_loss_by_nets = []\n",
    "test_loss_by_nets = []\n",
    "epoch_by_nets = []\n",
    "\n",
    "for num, net in enumerate(list_of_nets):\n",
    "    learn_loss = []\n",
    "    valid_loss = []\n",
    "    test_loss = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        loss_acc = []\n",
    "        for learn_data in learn_dataloader:\n",
    "            features, labels = learn_data[:, FEATURES_INDEX].float(), learn_data[:, LABELS_INDEX].float()\n",
    "            features.requres_grad = True\n",
    "            labels.requres_grad = True\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            loss = optimizer.step(closure)\n",
    "            loss_acc.append(float(loss))\n",
    "        learn_loss.append(np.mean(loss_acc))\n",
    "        \n",
    "        #критерий останова\n",
    "        if (epoch > 10) and\\\n",
    "        (abs(learn_loss[-1] - learn_loss[-2]) < LOSS_THRESHOLD):\n",
    "            print(learn_loss[-1] - learn_loss[-2])\n",
    "            print('net: ', num, ' \\n breaked on epoch: ', epoch, '\\n')\n",
    "            break\n",
    "            \n",
    "        if epoch % 100 == 0:\n",
    "            epoch_list.append(epoch)\n",
    "            for valid_data in valid_dataloader:\n",
    "                features, labels = valid_data[:, FEATURES_INDEX].float(), valid_data[:, LABELS_INDEX].float()\n",
    "                outputs = net(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss.append(float(loss))\n",
    "\n",
    "            for test_data in valid_dataloader:\n",
    "                features, labels = test_data[:, FEATURES_INDEX].float(), test_data[:, LABELS_INDEX].float()\n",
    "                outputs = net(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss.append(float(loss))\n",
    "                \n",
    "    learn_loss_by_nets.append(learn_loss)\n",
    "    valid_loss_by_nets.append(valid_loss)\n",
    "    test_loss_by_nets.append(test_loss)\n",
    "    epoch_by_nets.append(epoch_list)\n",
    "    torch.save(net.state_dict(), 'architecture/net'+str(num)+'_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn\n",
    "for num, net in enumerate(list_of_nets):\n",
    "    plt.plot(learn_loss_by_nets[num], label=str(num))\n",
    "plt.title('learn loss')\n",
    "plt.legend()\n",
    "plt.savefig('architecture/learn_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid\n",
    "for num, i in enumerate(list_of_nets):\n",
    "    plt.plot(epoch_by_nets[num], valid_loss_by_nets[num], label=str(num))\n",
    "plt.title('valid loss')\n",
    "plt.legend()\n",
    "plt.savefig('architecture/valid_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "for num, i in enumerate(list_of_nets):\n",
    "    plt.plot(epoch_by_nets[num], test_loss_by_nets[num], label=str(num))\n",
    "plt.title('test loss')\n",
    "plt.legend()\n",
    "plt.savefig('architecture/test_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print((learn_loss_by_nets[i]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
