{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.autograd as autograd\n",
    "from torch import optim\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "4601\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(filepath_or_buffer='spambase/spambase.data', header = None)\n",
    "inputs_indx = [x for x in range(57)]\n",
    "label_indx = 57\n",
    "print(len(dataset))\n",
    "dataset.drop_duplicates()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "dataset.loc[:, inputs_indx] = scaler.fit_transform(dataset.loc[:, inputs_indx])\n",
    "print(len(scaler.mean_))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.hist(dataset[i], bins = 15)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('hist1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.hist(dataset[i + 25], bins = 15)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('hist2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.hist(dataset[i + 50], bins = 15)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('hist3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset[i], vert=False)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset[i + 25], vert=False)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.boxplot(dataset[i + 50], vert=False)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('box3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset[dataset[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset[dataset[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset[dataset[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset[dataset[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_of_dataset = np.array(dataset.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spearman_of_dataset = np.array(dataset.corr(method='spearman'))\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(spearman_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(spearman_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_spearman.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kendal_of_dataset = np.array(dataset.corr(method='kendall'))\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(kendal_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(kendal_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_kendal.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [32, 51], [44, 52], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 56], [37, 55], [44, 43], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33], [54, 55]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    plt.scatter(dataset[atr_to_scatter[i][0]], dataset[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.OneClassSVM(kernel=\"rbf\")\n",
    "clf.fit(dataset[inputs_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIER_FRACTION = 0.05\n",
    "dist_to_border = clf.decision_function(dataset[inputs_indx]).ravel()\n",
    "threshold = stats.scoreatpercentile(dist_to_border,\n",
    "            100 * OUTLIER_FRACTION)\n",
    "is_inlier = dist_to_border > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([177.,  12.,   6.,   5.,   6.,   4.,   1.,   5.,   3.,   1.,   3.,\n",
       "          4.,   1.,   2.,   1.]),\n",
       " array([-6.3928493 , -6.39156876, -6.39028822, -6.38900768, -6.38772714,\n",
       "        -6.3864466 , -6.38516607, -6.38388553, -6.38260499, -6.38132445,\n",
       "        -6.38004391, -6.37876337, -6.37748283, -6.37620229, -6.37492175,\n",
       "        -6.37364121]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103884a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dist_to_border[is_inlier == False], bins = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230.05\n",
      "4370.95\n",
      "231\n",
      "4370\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...   48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.0  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.0  0.132   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.0  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.0  0.135   \n",
       "5  0.00  0.00  0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00 ...  0.0  0.223   \n",
       "\n",
       "    50     51    52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.00  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.18  0.048  5.114  101  1028   1  \n",
       "3  0.0  0.137  0.00  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.00  0.000  3.537   40   191   1  \n",
       "5  0.0  0.000  0.00  0.000  3.000   15    54   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_outlier = dataset[is_inlier == False]\n",
    "dataset_clear = dataset[is_inlier == True]\n",
    "print(len(dataset)*0.05)\n",
    "print(len(dataset)*0.95)\n",
    "print(len(dataset_outlier))\n",
    "print(len(dataset_clear))\n",
    "dataset_clear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset_clear[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('after_svm_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset_clear[i], vert=False)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset_clear[i + 25], vert=False)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.boxplot(dataset_clear[i + 50], vert=False)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('box3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset_clear[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('after_svm_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.135854</td>\n",
       "      <td>0.200392</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.165003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.103311</td>\n",
       "      <td>0.136036</td>\n",
       "      <td>0.124381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137004</td>\n",
       "      <td>0.115686</td>\n",
       "      <td>0.178431</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.138095</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0.105041</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.167687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.120011</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>0.123988</td>\n",
       "      <td>0.102925</td>\n",
       "      <td>0.104942</td>\n",
       "      <td>0.160060</td>\n",
       "      <td>0.190395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>0.145365</td>\n",
       "      <td>0.147148</td>\n",
       "      <td>0.145365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.120769</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.111446</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.103047</td>\n",
       "      <td>0.123423</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>0.145365</td>\n",
       "      <td>0.147148</td>\n",
       "      <td>0.145365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.120466</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.111279</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.103047</td>\n",
       "      <td>0.123423</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.233213</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.133807</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.102402</td>\n",
       "      <td>0.108408</td>\n",
       "      <td>0.104665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3       4         5         6         7   \\\n",
       "0  0.100000  0.135854  0.200392  0.1  0.1256  0.100000  0.100000  0.100000   \n",
       "1  0.137004  0.115686  0.178431  0.1  0.1112  0.138095  0.123109  0.105041   \n",
       "3  0.100000  0.100000  0.100000  0.1  0.1504  0.100000  0.134113  0.145365   \n",
       "4  0.100000  0.100000  0.100000  0.1  0.1504  0.100000  0.134113  0.145365   \n",
       "5  0.100000  0.100000  0.100000  0.1  0.2480  0.100000  0.100000  0.233213   \n",
       "\n",
       "         8         9  ...   48        49   50        51        52        53  \\\n",
       "0  0.100000  0.100000 ...  0.1  0.100000  0.1  0.165003  0.100000  0.100000   \n",
       "1  0.100000  0.167687 ...  0.1  0.120011  0.1  0.131081  0.123988  0.102925   \n",
       "3  0.147148  0.145365 ...  0.1  0.120769  0.1  0.111446  0.100000  0.100000   \n",
       "4  0.147148  0.145365 ...  0.1  0.120466  0.1  0.111279  0.100000  0.100000   \n",
       "5  0.100000  0.100000 ...  0.1  0.133807  0.1  0.100000  0.100000  0.100000   \n",
       "\n",
       "         54        55        56  57  \n",
       "0  0.103311  0.136036  0.124381   1  \n",
       "1  0.104942  0.160060  0.190395   1  \n",
       "3  0.103047  0.123423  0.116724   1  \n",
       "4  0.103047  0.123423  0.116724   1  \n",
       "5  0.102402  0.108408  0.104665   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clear.loc[:, inputs_indx] = preprocessing.minmax_scale(dataset_clear.loc[:, inputs_indx], feature_range=(0.1, 0.9))\n",
    "dataset_clear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4370 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "0     4370 non-null float64\n",
      "1     4370 non-null float64\n",
      "2     4370 non-null float64\n",
      "3     4370 non-null float64\n",
      "4     4370 non-null float64\n",
      "5     4370 non-null float64\n",
      "6     4370 non-null float64\n",
      "7     4370 non-null float64\n",
      "8     4370 non-null float64\n",
      "9     4370 non-null float64\n",
      "10    4370 non-null float64\n",
      "11    4370 non-null float64\n",
      "12    4370 non-null float64\n",
      "13    4370 non-null float64\n",
      "14    4370 non-null float64\n",
      "15    4370 non-null float64\n",
      "16    4370 non-null float64\n",
      "17    4370 non-null float64\n",
      "18    4370 non-null float64\n",
      "19    4370 non-null float64\n",
      "20    4370 non-null float64\n",
      "21    4370 non-null float64\n",
      "22    4370 non-null float64\n",
      "23    4370 non-null float64\n",
      "24    4370 non-null float64\n",
      "25    4370 non-null float64\n",
      "26    4370 non-null float64\n",
      "27    4370 non-null float64\n",
      "28    4370 non-null float64\n",
      "29    4370 non-null float64\n",
      "30    4370 non-null float64\n",
      "31    4370 non-null float64\n",
      "32    4370 non-null float64\n",
      "33    4370 non-null float64\n",
      "34    4370 non-null float64\n",
      "35    4370 non-null float64\n",
      "36    4370 non-null float64\n",
      "37    4370 non-null float64\n",
      "38    4370 non-null float64\n",
      "39    4370 non-null float64\n",
      "40    4370 non-null float64\n",
      "41    4370 non-null float64\n",
      "42    4370 non-null float64\n",
      "43    4370 non-null float64\n",
      "44    4370 non-null float64\n",
      "45    4370 non-null float64\n",
      "46    4370 non-null float64\n",
      "47    4370 non-null float64\n",
      "48    4370 non-null float64\n",
      "49    4370 non-null float64\n",
      "50    4370 non-null float64\n",
      "51    4370 non-null float64\n",
      "52    4370 non-null float64\n",
      "53    4370 non-null float64\n",
      "54    4370 non-null float64\n",
      "55    4370 non-null float64\n",
      "56    4370 non-null float64\n",
      "57    4370 non-null int64\n",
      "dtypes: float64(57), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_clear.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset_clear[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('scale_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset_clear[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('scale_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [32, 51], [44, 52], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 56], [37, 55], [44, 43], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33], [54, 55]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    plt.scatter(dataset_clear[atr_to_scatter[i][0]], dataset_clear[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('scale_scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_of_dataset_clear = np.array(dataset_clear.corr())\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_of_dataset_clear)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_of_dataset_clear, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr_clear.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_dataset = PCA(n_components=50).fit_transform(dataset_clear[inputs_indx])\n",
    "end_dataset = pd.DataFrame(end_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_features = features.corr()\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_features)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_features, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr_features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4370 entries, 0 to 4369\n",
      "Data columns (total 51 columns):\n",
      "0     4370 non-null float64\n",
      "1     4370 non-null float64\n",
      "2     4370 non-null float64\n",
      "3     4370 non-null float64\n",
      "4     4370 non-null float64\n",
      "5     4370 non-null float64\n",
      "6     4370 non-null float64\n",
      "7     4370 non-null float64\n",
      "8     4370 non-null float64\n",
      "9     4370 non-null float64\n",
      "10    4370 non-null float64\n",
      "11    4370 non-null float64\n",
      "12    4370 non-null float64\n",
      "13    4370 non-null float64\n",
      "14    4370 non-null float64\n",
      "15    4370 non-null float64\n",
      "16    4370 non-null float64\n",
      "17    4370 non-null float64\n",
      "18    4370 non-null float64\n",
      "19    4370 non-null float64\n",
      "20    4370 non-null float64\n",
      "21    4370 non-null float64\n",
      "22    4370 non-null float64\n",
      "23    4370 non-null float64\n",
      "24    4370 non-null float64\n",
      "25    4370 non-null float64\n",
      "26    4370 non-null float64\n",
      "27    4370 non-null float64\n",
      "28    4370 non-null float64\n",
      "29    4370 non-null float64\n",
      "30    4370 non-null float64\n",
      "31    4370 non-null float64\n",
      "32    4370 non-null float64\n",
      "33    4370 non-null float64\n",
      "34    4370 non-null float64\n",
      "35    4370 non-null float64\n",
      "36    4370 non-null float64\n",
      "37    4370 non-null float64\n",
      "38    4370 non-null float64\n",
      "39    4370 non-null float64\n",
      "40    4370 non-null float64\n",
      "41    4370 non-null float64\n",
      "42    4370 non-null float64\n",
      "43    4370 non-null float64\n",
      "44    4370 non-null float64\n",
      "45    4370 non-null float64\n",
      "46    4370 non-null float64\n",
      "47    4370 non-null float64\n",
      "48    4370 non-null float64\n",
      "49    4370 non-null float64\n",
      "50    4370 non-null int64\n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "end_dataset[50] = np.array(dataset_clear[57])\n",
    "end_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(features[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((features[labels == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((features[labels == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('end_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(features[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((features[labels == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((features[labels == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('end_scale_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [44, 45], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 16], [37, 35], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.scatter(features[atr_to_scatter[i][0]], features[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('end_scale_scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonspam_end_dataset = end_dataset[end_dataset[50] == 0]\n",
    "spam_end_dataset = end_dataset[end_dataset[50] == 1]\n",
    "nonspam_end_dataset = nonspam_end_dataset.reindex()\n",
    "spam_end_dataset= spam_end_dataset.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621 1311 438 4370 4370\n"
     ]
    }
   ],
   "source": [
    "rand_indxs_spam = np.arange(len(spam_end_dataset))\n",
    "rand_indxs_nonspam = np.arange(len(nonspam_end_dataset))\n",
    "\n",
    "np.random.shuffle(rand_indxs_spam)\n",
    "np.random.shuffle(rand_indxs_nonspam)\n",
    "\n",
    "f_threshold_spam = int(len(spam_end_dataset)*0.6)\n",
    "s_threshold_spam = int(len(spam_end_dataset)*0.9)\n",
    "\n",
    "f_threshold_nonspam = int(len(nonspam_end_dataset)*0.6)\n",
    "s_threshold_nonspam = int(len(nonspam_end_dataset)*0.9)\n",
    "\n",
    "learn_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[:f_threshold_spam]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[:f_threshold_nonspam]]])\n",
    "\n",
    "valid_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[f_threshold_spam:s_threshold_spam]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[f_threshold_nonspam:s_threshold_nonspam]]])\n",
    "\n",
    "test_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[s_threshold_spam:]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[s_threshold_nonspam:]]])\n",
    "\n",
    "print(len(learn_dataset), len(valid_dataset), len(test_dataset), len(learn_dataset)+len(valid_dataset)+len(test_dataset), len(end_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 438 entries, 1235 to 1998\n",
      "Data columns (total 51 columns):\n",
      "0     438 non-null float64\n",
      "1     438 non-null float64\n",
      "2     438 non-null float64\n",
      "3     438 non-null float64\n",
      "4     438 non-null float64\n",
      "5     438 non-null float64\n",
      "6     438 non-null float64\n",
      "7     438 non-null float64\n",
      "8     438 non-null float64\n",
      "9     438 non-null float64\n",
      "10    438 non-null float64\n",
      "11    438 non-null float64\n",
      "12    438 non-null float64\n",
      "13    438 non-null float64\n",
      "14    438 non-null float64\n",
      "15    438 non-null float64\n",
      "16    438 non-null float64\n",
      "17    438 non-null float64\n",
      "18    438 non-null float64\n",
      "19    438 non-null float64\n",
      "20    438 non-null float64\n",
      "21    438 non-null float64\n",
      "22    438 non-null float64\n",
      "23    438 non-null float64\n",
      "24    438 non-null float64\n",
      "25    438 non-null float64\n",
      "26    438 non-null float64\n",
      "27    438 non-null float64\n",
      "28    438 non-null float64\n",
      "29    438 non-null float64\n",
      "30    438 non-null float64\n",
      "31    438 non-null float64\n",
      "32    438 non-null float64\n",
      "33    438 non-null float64\n",
      "34    438 non-null float64\n",
      "35    438 non-null float64\n",
      "36    438 non-null float64\n",
      "37    438 non-null float64\n",
      "38    438 non-null float64\n",
      "39    438 non-null float64\n",
      "40    438 non-null float64\n",
      "41    438 non-null float64\n",
      "42    438 non-null float64\n",
      "43    438 non-null float64\n",
      "44    438 non-null float64\n",
      "45    438 non-null float64\n",
      "46    438 non-null float64\n",
      "47    438 non-null float64\n",
      "48    438 non-null float64\n",
      "49    438 non-null float64\n",
      "50    438 non-null int64\n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 177.9 KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_spam_data = np.array(MyDataset(learn_dataset))\n",
    "valid_spam_data = np.array(MyDataset(valid_dataset))\n",
    "test_spam_data = np.array(MyDataset(test_dataset))\n",
    "learn_dataloader = DataLoader(learn_spam_data, batch_size=1, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_spam_data, batch_size=len(valid_spam_data), shuffle=False)\n",
    "test_dataloader = DataLoader(test_spam_data, batch_size=len(test_spam_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2621, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_spam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lin3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, 20)\n",
    "        self.lin2 = nn.Linear(20, 10)\n",
    "        self.lin3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = np.arange(50)\n",
    "feature_index\n",
    "label_indx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lin3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def type_weights(layer):\n",
    "    if (type(layer) == nn.Linear):\n",
    "        print(layer.weight.requires_grad)\n",
    "net.apply(type_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.8242,  0.7004,  0.3072, -1.2434, -1.8036,  2.0332, -0.1901,\n",
       "          -3.2951,  0.1524, -2.4361]]),\n",
       " tensor([[ 0.5215, -0.0398,  0.3532, -0.2106,  0.1947,  0.2994,  0.2864,\n",
       "          -0.1077, -0.1327, -0.2516,  0.2884, -0.4215,  0.2027, -0.0369,\n",
       "          -0.0803, -0.2243, -0.0893, -0.2745,  0.4415,  0.1801],\n",
       "         [ 0.5082,  0.2228,  0.0843,  0.2600,  0.0130, -0.0799, -0.1130,\n",
       "           0.3192, -0.1232,  0.3718,  0.2303, -0.2321,  0.1181,  0.0353,\n",
       "           0.1382,  0.2937,  0.0585,  0.2822,  0.1687,  0.5539],\n",
       "         [ 0.0880, -0.1366,  0.0693, -0.4774,  0.0821,  0.0679,  0.0262,\n",
       "          -0.0193, -0.1309, -0.1938, -0.1193, -0.3216, -0.0945,  0.3427,\n",
       "          -0.0447,  0.2029, -0.0128, -0.0209, -0.3895, -0.1942],\n",
       "         [ 0.0210,  0.0601,  0.0086,  0.2002,  0.2496,  0.2307,  0.0728,\n",
       "          -0.2124,  0.2637, -0.0874, -0.0889,  0.0087,  0.5178, -0.0557,\n",
       "          -0.0259,  0.1338,  0.2185, -0.2478, -0.5010,  0.2518],\n",
       "         [ 0.0882,  0.5987,  0.2015, -0.0272,  0.2028, -0.4742,  0.4199,\n",
       "          -0.1454,  0.3005, -0.3841,  0.3377, -0.0239,  0.2105, -0.1339,\n",
       "           0.2734,  0.1738,  0.4060,  0.1424, -0.1050, -0.0009],\n",
       "         [ 0.1114,  0.6445,  0.0320,  0.1604, -0.1645,  0.5548, -0.2235,\n",
       "           0.1269, -0.2985,  0.1047, -0.0958,  0.0753,  0.1532, -0.2153,\n",
       "           0.2135, -0.1359, -0.0012, -0.5699, -0.4542,  0.3641],\n",
       "         [-0.0208, -0.5159,  0.1717, -0.0346,  0.0006,  0.2321,  0.2775,\n",
       "           0.0522, -0.0800, -0.3871, -0.0333,  0.3390, -0.2734,  0.2752,\n",
       "          -0.5453, -0.2291, -0.0733,  0.0828,  0.5187, -0.0693],\n",
       "         [-0.1296, -0.0222, -0.1554, -0.2482,  0.3503,  0.0929,  0.1870,\n",
       "          -0.5165,  0.0834,  0.2677, -0.6542,  0.1284,  0.3305, -0.3862,\n",
       "          -0.2494, -0.1628, -0.0205, -0.0155, -0.0235,  0.1260],\n",
       "         [-0.1607, -0.0300, -0.0501,  0.5075,  0.0225, -0.2221,  0.6883,\n",
       "           0.1485, -0.3597,  0.2486,  0.0961, -0.1027,  0.2920, -0.3039,\n",
       "          -0.1578, -0.1917, -0.0113, -0.1163,  0.0466, -0.0090],\n",
       "         [ 0.3175,  0.1527, -0.2574,  0.2004, -0.1941,  0.1008, -0.2894,\n",
       "           0.1641, -0.0993, -0.1721,  0.2330, -0.0223,  0.1688, -0.2922,\n",
       "          -0.7809, -0.0139, -0.2715, -0.0079, -0.0273,  0.2418]]),\n",
       " tensor([[ 0.0618, -0.2712,  0.0499,  0.1045,  0.0877,  0.1328, -0.0999,\n",
       "          -0.0189,  0.0997, -0.1746,  0.1796,  0.1290, -0.0507,  0.0419,\n",
       "          -0.1641, -0.0300,  0.2213,  0.0647, -0.1162,  0.0628, -0.0511,\n",
       "           0.0471, -0.3735, -0.2170, -0.1866, -0.2124,  0.1996, -0.1003,\n",
       "           0.1543, -0.2101,  0.0172,  0.1725, -0.0978,  0.0522,  0.1839,\n",
       "          -0.0895, -0.0089, -0.2060,  0.1258, -0.1166,  0.1359,  0.0752,\n",
       "           0.0973, -0.0602, -0.2644, -0.2689,  0.0941, -0.0097, -0.0586,\n",
       "          -0.0770],\n",
       "         [ 0.0972, -0.1239,  0.0150, -0.0995, -0.0652,  0.3730, -0.0239,\n",
       "           0.1005, -0.0452, -0.0260, -0.2350, -0.0311,  0.0290, -0.0684,\n",
       "           0.0447,  0.2495,  0.3102, -0.1836,  0.1692,  0.1416,  0.1609,\n",
       "           0.0162,  0.0915,  0.1943, -0.0752, -0.1539,  0.0644,  0.1224,\n",
       "           0.2695, -0.0283, -0.1122,  0.1587,  0.1334, -0.1256,  0.1076,\n",
       "          -0.0641,  0.0188, -0.0625, -0.0917,  0.0101, -0.0358, -0.0952,\n",
       "          -0.0855,  0.0272, -0.0764,  0.0522, -0.4731, -0.0875, -0.1469,\n",
       "          -0.0405],\n",
       "         [-0.0689,  0.1170,  0.1334, -0.0554, -0.0513,  0.1124,  0.1066,\n",
       "          -0.2019, -0.1479,  0.0051, -0.0217,  0.0752,  0.0618,  0.0360,\n",
       "           0.1648, -0.2918,  0.4061,  0.0538, -0.0368, -0.3097,  0.1379,\n",
       "           0.1857,  0.0157,  0.0701, -0.1736,  0.3484, -0.1906, -0.2606,\n",
       "          -0.1571, -0.0414,  0.0387,  0.1145, -0.1438, -0.1242, -0.1217,\n",
       "           0.0972,  0.1175, -0.1046, -0.1165,  0.2394,  0.1882,  0.0514,\n",
       "           0.2813,  0.0284,  0.2611, -0.0854, -0.1781, -0.1325,  0.0301,\n",
       "           0.1064],\n",
       "         [-0.2156, -0.0880,  0.1361, -0.0202,  0.2525, -0.0682, -0.2573,\n",
       "          -0.0319, -0.3179, -0.2174,  0.1582,  0.0172, -0.0116,  0.1643,\n",
       "           0.0318, -0.4945, -0.0700, -0.0241,  0.0627,  0.1405,  0.0959,\n",
       "          -0.4028, -0.0370,  0.1967,  0.3610,  0.2211, -0.0478, -0.1139,\n",
       "          -0.1621,  0.0085, -0.1488,  0.1196, -0.2319,  0.3885, -0.0406,\n",
       "           0.0130, -0.2813, -0.1547,  0.1756, -0.1087,  0.0881,  0.1648,\n",
       "           0.0261,  0.2633,  0.0516, -0.1047,  0.2338, -0.2598,  0.0289,\n",
       "           0.0431],\n",
       "         [-0.2076, -0.1491, -0.1108,  0.0149,  0.1013,  0.1850,  0.1288,\n",
       "           0.0708,  0.2061,  0.2174, -0.0057,  0.1167,  0.0045,  0.0445,\n",
       "           0.1784,  0.2320,  0.0173,  0.0771, -0.0732,  0.2135, -0.1453,\n",
       "           0.1136, -0.0605,  0.1538,  0.0072, -0.1142, -0.4441,  0.0037,\n",
       "           0.2009, -0.1990, -0.0992, -0.1010, -0.1691,  0.2472,  0.1473,\n",
       "          -0.3235,  0.0345,  0.1758, -0.2117,  0.0497, -0.2344, -0.0912,\n",
       "           0.0024,  0.2639,  0.3764,  0.1429, -0.2197, -0.0599, -0.2801,\n",
       "          -0.0178],\n",
       "         [ 0.0513,  0.1700, -0.1868, -0.0153,  0.4367,  0.0322, -0.2513,\n",
       "           0.0140,  0.2260,  0.0358, -0.1603, -0.2575,  0.0065,  0.0337,\n",
       "           0.0147,  0.3166, -0.1606, -0.0578,  0.1854, -0.0551, -0.0918,\n",
       "           0.1536,  0.2899, -0.0706,  0.3560, -0.1994,  0.0135,  0.0733,\n",
       "          -0.0899,  0.0840, -0.2536, -0.0745, -0.0967, -0.3502, -0.1486,\n",
       "          -0.1773, -0.1847,  0.0048,  0.2919, -0.1873,  0.0722,  0.1728,\n",
       "           0.2343,  0.0374,  0.0314, -0.0489, -0.1504, -0.4419,  0.0460,\n",
       "          -0.1429],\n",
       "         [-0.0131,  0.1652,  0.1805, -0.0356, -0.2092, -0.2649,  0.1272,\n",
       "          -0.1292, -0.0696, -0.0135,  0.0473,  0.0686, -0.2151,  0.0376,\n",
       "           0.1237, -0.0228, -0.0576, -0.0727,  0.2414,  0.1035,  0.0599,\n",
       "           0.0954, -0.0676,  0.3119,  0.2408, -0.0338,  0.2696,  0.0709,\n",
       "          -0.0109,  0.0054,  0.0563, -0.2145, -0.1829, -0.1222, -0.3075,\n",
       "           0.0914,  0.1943,  0.4316, -0.1963, -0.1377, -0.0624,  0.1368,\n",
       "          -0.1546, -0.1364, -0.1284, -0.1232,  0.1362,  0.0793, -0.1289,\n",
       "          -0.1327],\n",
       "         [ 0.1343, -0.0576, -0.0888, -0.0385,  0.1363, -0.2518,  0.3357,\n",
       "           0.0339,  0.1054,  0.2549, -0.2830, -0.0485,  0.1445,  0.0457,\n",
       "           0.0346,  0.0096,  0.0191, -0.1702,  0.0039, -0.1022, -0.1096,\n",
       "          -0.2820,  0.0978,  0.0055,  0.0248, -0.1056,  0.0148, -0.0476,\n",
       "           0.0762,  0.2709,  0.0259, -0.1273,  0.1277, -0.1287,  0.1307,\n",
       "           0.0021,  0.0662,  0.1166,  0.2841,  0.0869, -0.0968, -0.0647,\n",
       "           0.1776,  0.2040,  0.0666,  0.2158,  0.3325,  0.1562,  0.2369,\n",
       "           0.2742],\n",
       "         [ 0.0946,  0.0318,  0.0256, -0.2001,  0.3068,  0.1887,  0.0238,\n",
       "           0.1428,  0.1806,  0.1699, -0.2579, -0.1592,  0.1852, -0.0881,\n",
       "           0.0311, -0.3378, -0.1723,  0.1478,  0.1151,  0.1695,  0.1456,\n",
       "           0.2234,  0.0429, -0.3617, -0.0877,  0.3747, -0.2166,  0.0016,\n",
       "          -0.0616,  0.2080, -0.2729, -0.0262, -0.1688, -0.1688,  0.1468,\n",
       "          -0.2966,  0.1233, -0.1705,  0.0053,  0.2269,  0.1017,  0.0261,\n",
       "          -0.0993, -0.2096,  0.0609, -0.2138,  0.0362,  0.3362, -0.0037,\n",
       "           0.3411],\n",
       "         [-0.1332,  0.2313,  0.3080, -0.0409,  0.0775,  0.1398, -0.2856,\n",
       "           0.0621,  0.0437,  0.0175,  0.0356, -0.3509,  0.0942, -0.1319,\n",
       "           0.2850, -0.0796, -0.0324, -0.1613,  0.2264, -0.0561,  0.1007,\n",
       "          -0.0664,  0.0826,  0.0925, -0.1782,  0.1592,  0.0094,  0.0460,\n",
       "          -0.0178,  0.0595,  0.0832, -0.3360, -0.0465,  0.0331, -0.2969,\n",
       "          -0.0658,  0.1899,  0.0233,  0.0225,  0.1102, -0.1617, -0.0228,\n",
       "           0.0782,  0.0627,  0.2399,  0.1692,  0.0139, -0.1365, -0.0436,\n",
       "           0.1307],\n",
       "         [ 0.0382, -0.1510,  0.0090, -0.0871, -0.3165,  0.1828,  0.0556,\n",
       "           0.0282,  0.0160, -0.0096,  0.4260,  0.1529,  0.1292,  0.0860,\n",
       "          -0.1442, -0.1804,  0.0934,  0.0003,  0.0658,  0.2408,  0.2192,\n",
       "          -0.1473,  0.2000,  0.1201,  0.2364,  0.1155,  0.0144,  0.1781,\n",
       "           0.3174,  0.0034,  0.0550,  0.2450, -0.2270, -0.0681, -0.0176,\n",
       "          -0.2574,  0.0704, -0.0966, -0.0744,  0.0293, -0.1736, -0.1513,\n",
       "           0.0189,  0.1755,  0.0785, -0.2180,  0.1660, -0.2496, -0.2119,\n",
       "          -0.0853],\n",
       "         [ 0.1292,  0.2375, -0.3154, -0.0851, -0.3928, -0.0781,  0.1009,\n",
       "          -0.0112, -0.0787, -0.1532, -0.1795, -0.0133, -0.0333, -0.1592,\n",
       "           0.2022, -0.1592,  0.0645, -0.2292, -0.3133, -0.0671,  0.3303,\n",
       "           0.1549, -0.0803, -0.1361,  0.0128,  0.1866,  0.0152,  0.0626,\n",
       "          -0.0464, -0.1877, -0.1179, -0.2398, -0.0664,  0.2853, -0.0194,\n",
       "           0.0936,  0.1568, -0.0818, -0.1556,  0.0855, -0.1124, -0.1319,\n",
       "          -0.1804, -0.0950,  0.1033, -0.1614, -0.2521,  0.1767, -0.0609,\n",
       "           0.4731],\n",
       "         [ 0.1968,  0.2578, -0.0556,  0.2678, -0.0163, -0.1153,  0.0365,\n",
       "          -0.0395,  0.4097,  0.0245, -0.0436, -0.2568,  0.1298, -0.1295,\n",
       "          -0.4529, -0.0944,  0.0172,  0.0238, -0.1278,  0.0476, -0.1909,\n",
       "           0.1361,  0.0122, -0.0543, -0.0262,  0.0011,  0.0230, -0.0362,\n",
       "          -0.3758, -0.1760, -0.0285, -0.1377, -0.2650,  0.0890,  0.0008,\n",
       "          -0.0447,  0.0032,  0.1256, -0.5734, -0.2075,  0.1408, -0.2865,\n",
       "          -0.3096, -0.0748, -0.2966,  0.1051, -0.0150,  0.4213,  0.2648,\n",
       "          -0.0670],\n",
       "         [-0.1372, -0.2253, -0.2330, -0.0578,  0.3093,  0.0441, -0.1031,\n",
       "          -0.0393, -0.0286,  0.4494,  0.0119, -0.1937, -0.2115, -0.2673,\n",
       "          -0.3305,  0.0201, -0.0067, -0.0142, -0.3479,  0.1992,  0.1692,\n",
       "          -0.1647, -0.0426, -0.0685,  0.0249,  0.2060,  0.2309,  0.1955,\n",
       "          -0.1281,  0.1960, -0.0663,  0.1834,  0.1091, -0.3123, -0.2626,\n",
       "           0.2988, -0.1259, -0.1490,  0.0250, -0.0324, -0.1436, -0.2741,\n",
       "           0.1105,  0.0580, -0.2071, -0.2053, -0.1877,  0.0709,  0.0581,\n",
       "          -0.1793],\n",
       "         [ 0.1177,  0.1717,  0.1339,  0.0101,  0.1335, -0.0651,  0.1286,\n",
       "           0.1882,  0.0094, -0.0332, -0.1042,  0.0709,  0.1067, -0.3067,\n",
       "          -0.0582, -0.3441,  0.0222, -0.1453, -0.2325,  0.0913,  0.0555,\n",
       "          -0.1654, -0.0046,  0.2188, -0.1033, -0.1759, -0.0886, -0.0358,\n",
       "          -0.1932,  0.1371, -0.2055, -0.2619, -0.0481,  0.1009, -0.1425,\n",
       "          -0.1715,  0.2434, -0.2664,  0.3456, -0.0775, -0.1102,  0.0688,\n",
       "          -0.1078,  0.1209, -0.1150,  0.3753,  0.1679, -0.0416, -0.2503,\n",
       "           0.0265],\n",
       "         [-0.1423,  0.0190,  0.2569,  0.0191,  0.0467,  0.1343,  0.2413,\n",
       "           0.1958, -0.0791, -0.4359, -0.1102,  0.0669, -0.0795, -0.3325,\n",
       "           0.1432, -0.1007,  0.0693,  0.0456, -0.2436, -0.2043,  0.0952,\n",
       "          -0.1087,  0.0694, -0.0701, -0.0529, -0.0059, -0.1083,  0.1623,\n",
       "          -0.1810,  0.0038,  0.0620,  0.0253, -0.0637,  0.3737, -0.2120,\n",
       "          -0.0402, -0.1354,  0.1582,  0.3031, -0.3569, -0.1210, -0.3524,\n",
       "          -0.0148,  0.0144,  0.0234,  0.1727,  0.0158,  0.0780, -0.1389,\n",
       "           0.1419],\n",
       "         [ 0.0092,  0.0787, -0.0370,  0.2067, -0.1519, -0.3709, -0.0154,\n",
       "          -0.0497, -0.2674,  0.0061,  0.1207,  0.1271,  0.3277, -0.0554,\n",
       "          -0.1563,  0.0310, -0.0573, -0.0798,  0.0018, -0.3934,  0.0125,\n",
       "          -0.0210,  0.2342,  0.0673, -0.0569, -0.1252,  0.0800, -0.0282,\n",
       "           0.1905,  0.0872,  0.0211, -0.1329, -0.1152, -0.1646,  0.0407,\n",
       "           0.2139, -0.2736,  0.1537, -0.3627, -0.1583,  0.1851,  0.0697,\n",
       "          -0.3248,  0.0803,  0.1153, -0.0170,  0.1218,  0.0902, -0.0457,\n",
       "          -0.0988],\n",
       "         [ 0.0023, -0.0191,  0.1028, -0.0189,  0.0223,  0.0235, -0.0883,\n",
       "           0.2333,  0.0580,  0.0366,  0.0155,  0.1169,  0.0740,  0.0009,\n",
       "           0.3870, -0.2481, -0.1971,  0.2279, -0.1799,  0.1005,  0.0090,\n",
       "           0.5081, -0.1568, -0.2576, -0.0417,  0.2029,  0.0863,  0.0276,\n",
       "           0.1243,  0.2717,  0.3178,  0.0332,  0.1366, -0.3546,  0.1751,\n",
       "           0.2926, -0.0618, -0.0522,  0.0033, -0.2460, -0.0376, -0.1219,\n",
       "          -0.0181,  0.1786, -0.1162, -0.0308,  0.4111, -0.2144,  0.0184,\n",
       "          -0.0125],\n",
       "         [ 0.0432,  0.3749,  0.2280, -0.2264, -0.0169, -0.2793, -0.1612,\n",
       "           0.3208, -0.1051, -0.1497,  0.2597, -0.1352,  0.1484,  0.0152,\n",
       "          -0.2424, -0.1717,  0.0253, -0.1748,  0.3492,  0.0540,  0.0190,\n",
       "           0.0394, -0.0534,  0.0980, -0.0062,  0.1136,  0.1332, -0.3266,\n",
       "           0.2120,  0.0379,  0.0290, -0.0847, -0.0799,  0.1001, -0.1253,\n",
       "          -0.0016, -0.1366, -0.0814,  0.5048,  0.0060,  0.1048,  0.1094,\n",
       "          -0.2291,  0.0406,  0.0026,  0.1300, -0.0887, -0.3014, -0.1613,\n",
       "          -0.0347],\n",
       "         [ 0.5587, -0.2079, -0.0384,  0.1025, -0.0308, -0.1086,  0.2005,\n",
       "           0.1754, -0.0112,  0.0082,  0.0959,  0.0979, -0.2000, -0.0601,\n",
       "           0.1329,  0.2444, -0.0035, -0.0300,  0.0765, -0.0837,  0.1909,\n",
       "           0.0301,  0.1299, -0.0745, -0.0873,  0.1258, -0.1683,  0.0767,\n",
       "          -0.0719, -0.0310, -0.1521, -0.1125, -0.0472,  0.2536, -0.1228,\n",
       "          -0.1122,  0.4611,  0.0539, -0.1764,  0.1266,  0.0190,  0.1045,\n",
       "          -0.1860, -0.0969, -0.2961,  0.1330, -0.4158,  0.0414, -0.2321,\n",
       "          -0.2965]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Инициализация весов\n",
    "stds = [(2/(50+20+1))**(1/2), (2/(20+10+1))**(1/2), (32/(10+1+1))**(1/2)]\n",
    "null_weigth = []\n",
    "stds.reverse()\n",
    "def get_weights(layer):\n",
    "    if (type(layer) == nn.Linear):\n",
    "        null_weigth.append(torch.randn(layer.weight.data.shape)*stds.pop())\n",
    "net.apply(get_weights)\n",
    "null_weigth.reverse()\n",
    "null_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0618, -0.2712,  0.0499,  0.1045,  0.0877,  0.1328, -0.0999,\n",
       "         -0.0189,  0.0997, -0.1746,  0.1796,  0.1290, -0.0507,  0.0419,\n",
       "         -0.1641, -0.0300,  0.2213,  0.0647, -0.1162,  0.0628, -0.0511,\n",
       "          0.0471, -0.3735, -0.2170, -0.1866, -0.2124,  0.1996, -0.1003,\n",
       "          0.1543, -0.2101,  0.0172,  0.1725, -0.0978,  0.0522,  0.1839,\n",
       "         -0.0895, -0.0089, -0.2060,  0.1258, -0.1166,  0.1359,  0.0752,\n",
       "          0.0973, -0.0602, -0.2644, -0.2689,  0.0941, -0.0097, -0.0586,\n",
       "         -0.0770],\n",
       "        [ 0.0972, -0.1239,  0.0150, -0.0995, -0.0652,  0.3730, -0.0239,\n",
       "          0.1005, -0.0452, -0.0260, -0.2350, -0.0311,  0.0290, -0.0684,\n",
       "          0.0447,  0.2495,  0.3102, -0.1836,  0.1692,  0.1416,  0.1609,\n",
       "          0.0162,  0.0915,  0.1943, -0.0752, -0.1539,  0.0644,  0.1224,\n",
       "          0.2695, -0.0283, -0.1122,  0.1587,  0.1334, -0.1256,  0.1076,\n",
       "         -0.0641,  0.0188, -0.0625, -0.0917,  0.0101, -0.0358, -0.0952,\n",
       "         -0.0855,  0.0272, -0.0764,  0.0522, -0.4731, -0.0875, -0.1469,\n",
       "         -0.0405],\n",
       "        [-0.0689,  0.1170,  0.1334, -0.0554, -0.0513,  0.1124,  0.1066,\n",
       "         -0.2019, -0.1479,  0.0051, -0.0217,  0.0752,  0.0618,  0.0360,\n",
       "          0.1648, -0.2918,  0.4061,  0.0538, -0.0368, -0.3097,  0.1379,\n",
       "          0.1857,  0.0157,  0.0701, -0.1736,  0.3484, -0.1906, -0.2606,\n",
       "         -0.1571, -0.0414,  0.0387,  0.1145, -0.1438, -0.1242, -0.1217,\n",
       "          0.0972,  0.1175, -0.1046, -0.1165,  0.2394,  0.1882,  0.0514,\n",
       "          0.2813,  0.0284,  0.2611, -0.0854, -0.1781, -0.1325,  0.0301,\n",
       "          0.1064],\n",
       "        [-0.2156, -0.0880,  0.1361, -0.0202,  0.2525, -0.0682, -0.2573,\n",
       "         -0.0319, -0.3179, -0.2174,  0.1582,  0.0172, -0.0116,  0.1643,\n",
       "          0.0318, -0.4945, -0.0700, -0.0241,  0.0627,  0.1405,  0.0959,\n",
       "         -0.4028, -0.0370,  0.1967,  0.3610,  0.2211, -0.0478, -0.1139,\n",
       "         -0.1621,  0.0085, -0.1488,  0.1196, -0.2319,  0.3885, -0.0406,\n",
       "          0.0130, -0.2813, -0.1547,  0.1756, -0.1087,  0.0881,  0.1648,\n",
       "          0.0261,  0.2633,  0.0516, -0.1047,  0.2338, -0.2598,  0.0289,\n",
       "          0.0431],\n",
       "        [-0.2076, -0.1491, -0.1108,  0.0149,  0.1013,  0.1850,  0.1288,\n",
       "          0.0708,  0.2061,  0.2174, -0.0057,  0.1167,  0.0045,  0.0445,\n",
       "          0.1784,  0.2320,  0.0173,  0.0771, -0.0732,  0.2135, -0.1453,\n",
       "          0.1136, -0.0605,  0.1538,  0.0072, -0.1142, -0.4441,  0.0037,\n",
       "          0.2009, -0.1990, -0.0992, -0.1010, -0.1691,  0.2472,  0.1473,\n",
       "         -0.3235,  0.0345,  0.1758, -0.2117,  0.0497, -0.2344, -0.0912,\n",
       "          0.0024,  0.2639,  0.3764,  0.1429, -0.2197, -0.0599, -0.2801,\n",
       "         -0.0178],\n",
       "        [ 0.0513,  0.1700, -0.1868, -0.0153,  0.4367,  0.0322, -0.2513,\n",
       "          0.0140,  0.2260,  0.0358, -0.1603, -0.2575,  0.0065,  0.0337,\n",
       "          0.0147,  0.3166, -0.1606, -0.0578,  0.1854, -0.0551, -0.0918,\n",
       "          0.1536,  0.2899, -0.0706,  0.3560, -0.1994,  0.0135,  0.0733,\n",
       "         -0.0899,  0.0840, -0.2536, -0.0745, -0.0967, -0.3502, -0.1486,\n",
       "         -0.1773, -0.1847,  0.0048,  0.2919, -0.1873,  0.0722,  0.1728,\n",
       "          0.2343,  0.0374,  0.0314, -0.0489, -0.1504, -0.4419,  0.0460,\n",
       "         -0.1429],\n",
       "        [-0.0131,  0.1652,  0.1805, -0.0356, -0.2092, -0.2649,  0.1272,\n",
       "         -0.1292, -0.0696, -0.0135,  0.0473,  0.0686, -0.2151,  0.0376,\n",
       "          0.1237, -0.0228, -0.0576, -0.0727,  0.2414,  0.1035,  0.0599,\n",
       "          0.0954, -0.0676,  0.3119,  0.2408, -0.0338,  0.2696,  0.0709,\n",
       "         -0.0109,  0.0054,  0.0563, -0.2145, -0.1829, -0.1222, -0.3075,\n",
       "          0.0914,  0.1943,  0.4316, -0.1963, -0.1377, -0.0624,  0.1368,\n",
       "         -0.1546, -0.1364, -0.1284, -0.1232,  0.1362,  0.0793, -0.1289,\n",
       "         -0.1327],\n",
       "        [ 0.1343, -0.0576, -0.0888, -0.0385,  0.1363, -0.2518,  0.3357,\n",
       "          0.0339,  0.1054,  0.2549, -0.2830, -0.0485,  0.1445,  0.0457,\n",
       "          0.0346,  0.0096,  0.0191, -0.1702,  0.0039, -0.1022, -0.1096,\n",
       "         -0.2820,  0.0978,  0.0055,  0.0248, -0.1056,  0.0148, -0.0476,\n",
       "          0.0762,  0.2709,  0.0259, -0.1273,  0.1277, -0.1287,  0.1307,\n",
       "          0.0021,  0.0662,  0.1166,  0.2841,  0.0869, -0.0968, -0.0647,\n",
       "          0.1776,  0.2040,  0.0666,  0.2158,  0.3325,  0.1562,  0.2369,\n",
       "          0.2742],\n",
       "        [ 0.0946,  0.0318,  0.0256, -0.2001,  0.3068,  0.1887,  0.0238,\n",
       "          0.1428,  0.1806,  0.1699, -0.2579, -0.1592,  0.1852, -0.0881,\n",
       "          0.0311, -0.3378, -0.1723,  0.1478,  0.1151,  0.1695,  0.1456,\n",
       "          0.2234,  0.0429, -0.3617, -0.0877,  0.3747, -0.2166,  0.0016,\n",
       "         -0.0616,  0.2080, -0.2729, -0.0262, -0.1688, -0.1688,  0.1468,\n",
       "         -0.2966,  0.1233, -0.1705,  0.0053,  0.2269,  0.1017,  0.0261,\n",
       "         -0.0993, -0.2096,  0.0609, -0.2138,  0.0362,  0.3362, -0.0037,\n",
       "          0.3411],\n",
       "        [-0.1332,  0.2313,  0.3080, -0.0409,  0.0775,  0.1398, -0.2856,\n",
       "          0.0621,  0.0437,  0.0175,  0.0356, -0.3509,  0.0942, -0.1319,\n",
       "          0.2850, -0.0796, -0.0324, -0.1613,  0.2264, -0.0561,  0.1007,\n",
       "         -0.0664,  0.0826,  0.0925, -0.1782,  0.1592,  0.0094,  0.0460,\n",
       "         -0.0178,  0.0595,  0.0832, -0.3360, -0.0465,  0.0331, -0.2969,\n",
       "         -0.0658,  0.1899,  0.0233,  0.0225,  0.1102, -0.1617, -0.0228,\n",
       "          0.0782,  0.0627,  0.2399,  0.1692,  0.0139, -0.1365, -0.0436,\n",
       "          0.1307],\n",
       "        [ 0.0382, -0.1510,  0.0090, -0.0871, -0.3165,  0.1828,  0.0556,\n",
       "          0.0282,  0.0160, -0.0096,  0.4260,  0.1529,  0.1292,  0.0860,\n",
       "         -0.1442, -0.1804,  0.0934,  0.0003,  0.0658,  0.2408,  0.2192,\n",
       "         -0.1473,  0.2000,  0.1201,  0.2364,  0.1155,  0.0144,  0.1781,\n",
       "          0.3174,  0.0034,  0.0550,  0.2450, -0.2270, -0.0681, -0.0176,\n",
       "         -0.2574,  0.0704, -0.0966, -0.0744,  0.0293, -0.1736, -0.1513,\n",
       "          0.0189,  0.1755,  0.0785, -0.2180,  0.1660, -0.2496, -0.2119,\n",
       "         -0.0853],\n",
       "        [ 0.1292,  0.2375, -0.3154, -0.0851, -0.3928, -0.0781,  0.1009,\n",
       "         -0.0112, -0.0787, -0.1532, -0.1795, -0.0133, -0.0333, -0.1592,\n",
       "          0.2022, -0.1592,  0.0645, -0.2292, -0.3133, -0.0671,  0.3303,\n",
       "          0.1549, -0.0803, -0.1361,  0.0128,  0.1866,  0.0152,  0.0626,\n",
       "         -0.0464, -0.1877, -0.1179, -0.2398, -0.0664,  0.2853, -0.0194,\n",
       "          0.0936,  0.1568, -0.0818, -0.1556,  0.0855, -0.1124, -0.1319,\n",
       "         -0.1804, -0.0950,  0.1033, -0.1614, -0.2521,  0.1767, -0.0609,\n",
       "          0.4731],\n",
       "        [ 0.1968,  0.2578, -0.0556,  0.2678, -0.0163, -0.1153,  0.0365,\n",
       "         -0.0395,  0.4097,  0.0245, -0.0436, -0.2568,  0.1298, -0.1295,\n",
       "         -0.4529, -0.0944,  0.0172,  0.0238, -0.1278,  0.0476, -0.1909,\n",
       "          0.1361,  0.0122, -0.0543, -0.0262,  0.0011,  0.0230, -0.0362,\n",
       "         -0.3758, -0.1760, -0.0285, -0.1377, -0.2650,  0.0890,  0.0008,\n",
       "         -0.0447,  0.0032,  0.1256, -0.5734, -0.2075,  0.1408, -0.2865,\n",
       "         -0.3096, -0.0748, -0.2966,  0.1051, -0.0150,  0.4213,  0.2648,\n",
       "         -0.0670],\n",
       "        [-0.1372, -0.2253, -0.2330, -0.0578,  0.3093,  0.0441, -0.1031,\n",
       "         -0.0393, -0.0286,  0.4494,  0.0119, -0.1937, -0.2115, -0.2673,\n",
       "         -0.3305,  0.0201, -0.0067, -0.0142, -0.3479,  0.1992,  0.1692,\n",
       "         -0.1647, -0.0426, -0.0685,  0.0249,  0.2060,  0.2309,  0.1955,\n",
       "         -0.1281,  0.1960, -0.0663,  0.1834,  0.1091, -0.3123, -0.2626,\n",
       "          0.2988, -0.1259, -0.1490,  0.0250, -0.0324, -0.1436, -0.2741,\n",
       "          0.1105,  0.0580, -0.2071, -0.2053, -0.1877,  0.0709,  0.0581,\n",
       "         -0.1793],\n",
       "        [ 0.1177,  0.1717,  0.1339,  0.0101,  0.1335, -0.0651,  0.1286,\n",
       "          0.1882,  0.0094, -0.0332, -0.1042,  0.0709,  0.1067, -0.3067,\n",
       "         -0.0582, -0.3441,  0.0222, -0.1453, -0.2325,  0.0913,  0.0555,\n",
       "         -0.1654, -0.0046,  0.2188, -0.1033, -0.1759, -0.0886, -0.0358,\n",
       "         -0.1932,  0.1371, -0.2055, -0.2619, -0.0481,  0.1009, -0.1425,\n",
       "         -0.1715,  0.2434, -0.2664,  0.3456, -0.0775, -0.1102,  0.0688,\n",
       "         -0.1078,  0.1209, -0.1150,  0.3753,  0.1679, -0.0416, -0.2503,\n",
       "          0.0265],\n",
       "        [-0.1423,  0.0190,  0.2569,  0.0191,  0.0467,  0.1343,  0.2413,\n",
       "          0.1958, -0.0791, -0.4359, -0.1102,  0.0669, -0.0795, -0.3325,\n",
       "          0.1432, -0.1007,  0.0693,  0.0456, -0.2436, -0.2043,  0.0952,\n",
       "         -0.1087,  0.0694, -0.0701, -0.0529, -0.0059, -0.1083,  0.1623,\n",
       "         -0.1810,  0.0038,  0.0620,  0.0253, -0.0637,  0.3737, -0.2120,\n",
       "         -0.0402, -0.1354,  0.1582,  0.3031, -0.3569, -0.1210, -0.3524,\n",
       "         -0.0148,  0.0144,  0.0234,  0.1727,  0.0158,  0.0780, -0.1389,\n",
       "          0.1419],\n",
       "        [ 0.0092,  0.0787, -0.0370,  0.2067, -0.1519, -0.3709, -0.0154,\n",
       "         -0.0497, -0.2674,  0.0061,  0.1207,  0.1271,  0.3277, -0.0554,\n",
       "         -0.1563,  0.0310, -0.0573, -0.0798,  0.0018, -0.3934,  0.0125,\n",
       "         -0.0210,  0.2342,  0.0673, -0.0569, -0.1252,  0.0800, -0.0282,\n",
       "          0.1905,  0.0872,  0.0211, -0.1329, -0.1152, -0.1646,  0.0407,\n",
       "          0.2139, -0.2736,  0.1537, -0.3627, -0.1583,  0.1851,  0.0697,\n",
       "         -0.3248,  0.0803,  0.1153, -0.0170,  0.1218,  0.0902, -0.0457,\n",
       "         -0.0988],\n",
       "        [ 0.0023, -0.0191,  0.1028, -0.0189,  0.0223,  0.0235, -0.0883,\n",
       "          0.2333,  0.0580,  0.0366,  0.0155,  0.1169,  0.0740,  0.0009,\n",
       "          0.3870, -0.2481, -0.1971,  0.2279, -0.1799,  0.1005,  0.0090,\n",
       "          0.5081, -0.1568, -0.2576, -0.0417,  0.2029,  0.0863,  0.0276,\n",
       "          0.1243,  0.2717,  0.3178,  0.0332,  0.1366, -0.3546,  0.1751,\n",
       "          0.2926, -0.0618, -0.0522,  0.0033, -0.2460, -0.0376, -0.1219,\n",
       "         -0.0181,  0.1786, -0.1162, -0.0308,  0.4111, -0.2144,  0.0184,\n",
       "         -0.0125],\n",
       "        [ 0.0432,  0.3749,  0.2280, -0.2264, -0.0169, -0.2793, -0.1612,\n",
       "          0.3208, -0.1051, -0.1497,  0.2597, -0.1352,  0.1484,  0.0152,\n",
       "         -0.2424, -0.1717,  0.0253, -0.1748,  0.3492,  0.0540,  0.0190,\n",
       "          0.0394, -0.0534,  0.0980, -0.0062,  0.1136,  0.1332, -0.3266,\n",
       "          0.2120,  0.0379,  0.0290, -0.0847, -0.0799,  0.1001, -0.1253,\n",
       "         -0.0016, -0.1366, -0.0814,  0.5048,  0.0060,  0.1048,  0.1094,\n",
       "         -0.2291,  0.0406,  0.0026,  0.1300, -0.0887, -0.3014, -0.1613,\n",
       "         -0.0347],\n",
       "        [ 0.5587, -0.2079, -0.0384,  0.1025, -0.0308, -0.1086,  0.2005,\n",
       "          0.1754, -0.0112,  0.0082,  0.0959,  0.0979, -0.2000, -0.0601,\n",
       "          0.1329,  0.2444, -0.0035, -0.0300,  0.0765, -0.0837,  0.1909,\n",
       "          0.0301,  0.1299, -0.0745, -0.0873,  0.1258, -0.1683,  0.0767,\n",
       "         -0.0719, -0.0310, -0.1521, -0.1125, -0.0472,  0.2536, -0.1228,\n",
       "         -0.1122,  0.4611,  0.0539, -0.1764,  0.1266,  0.0190,  0.1045,\n",
       "         -0.1860, -0.0969, -0.2961,  0.1330, -0.4158,  0.0414, -0.2321,\n",
       "         -0.2965]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_null_weigth = []\n",
    "for i in range(len(null_weigth)):\n",
    "    tmp_null_weigth.append(np.copy(null_weigth[i]))\n",
    "def init_weigths(layer):\n",
    "    if(type(layer) == nn.Linear):\n",
    "        layer.weight.data = torch.from_numpy(tmp_null_weigth.pop())\n",
    "net.apply(init_weigths)\n",
    "net.lin1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1311, 1])) that is different to the input size (torch.Size([1311, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([438, 1])) that is different to the input size (torch.Size([438, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "lr=0.0001\n",
    "for mu in [0, 0.75, 0.4, 0.15]:\n",
    "    tmp_null_weigth = []\n",
    "    for i in range(len(null_weigth)):\n",
    "        tmp_null_weigth.append(np.copy(null_weigth[i]))\n",
    "    net.apply(init_weigths)\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=mu)\n",
    "    \n",
    "    learn_epoch_loss = []\n",
    "    valid_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "    epoch_list = []\n",
    "    for epoch in range(550):#10**5:\n",
    "        loss_acc = 0\n",
    "\n",
    "        for learn_data in learn_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            features_learn, labels_learn = learn_data[:, feature_index], learn_data[:, label_indx]\n",
    "            features_learn, labels_learn  = autograd.Variable((features_learn).float()).unsqueeze(1), autograd.Variable(labels_learn.float()).unsqueeze(1)\n",
    "            outputs_learn = net(features_learn)\n",
    "            loss_learn = criterion(outputs_learn, labels_learn)\n",
    "            loss_learn.backward()\n",
    "            optimizer.step()\n",
    "            loss_acc += float(loss_learn.data)\n",
    "        learn_epoch_loss.append(loss_acc/len(learn_dataloader))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            epoch_list.append(epoch)\n",
    "            for valid_data in valid_dataloader:\n",
    "                features_valid, labels_valid = valid_data[:, feature_index], valid_data[:, label_indx]\n",
    "                features_valid, labels_valid  = autograd.Variable((features_valid).float()).unsqueeze(1), autograd.Variable(labels_valid.float()).unsqueeze(1)\n",
    "                outputs_valid = net(features_valid)\n",
    "                loss_valid = criterion(outputs_valid, labels_valid)\n",
    "                valid_epoch_loss.append(float(loss_valid.data))\n",
    "\n",
    "            for test_data in test_dataloader:\n",
    "                features_test, labels_test = test_data[:, feature_index], test_data[:, label_indx]\n",
    "                features_test, labels_test  = autograd.Variable((features_test).float()).unsqueeze(1), autograd.Variable(labels_test.float()).unsqueeze(1)\n",
    "                outputs_test = net(features_test)\n",
    "                loss_test = criterion(outputs_test, labels_test)\n",
    "                test_epoch_loss.append(float(loss_test.data))\n",
    "\n",
    "    plt.clf()\n",
    "    plt.grid(True)\n",
    "    plt.plot(learn_epoch_loss, color='r') \n",
    "    plt.plot(epoch_list, valid_epoch_loss, color='b') \n",
    "    plt.plot(epoch_list,  test_epoch_loss, color='g')\n",
    "    plt.title('mu = '+str(mu))\n",
    "    plt.savefig('gd_moment '+str(mu)+' learn: '+str(learn_epoch_loss[len(learn_epoch_loss)-1])+' test '+str(test_epoch_loss[len(test_epoch_loss)-1])+'.png')\n",
    "            #display.clear_output(wait=True) \n",
    "            #display.display(plt.gcf()) \n",
    "\n",
    "            #print(epoch, end=\" \")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
