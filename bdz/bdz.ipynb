{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.autograd as autograd\n",
    "from torch import optim\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "4601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        3.756\n",
       "1        5.114\n",
       "2        9.821\n",
       "3        3.537\n",
       "4        3.537\n",
       "5        3.000\n",
       "6        1.671\n",
       "7        2.450\n",
       "8        9.744\n",
       "9        1.729\n",
       "10       1.312\n",
       "11       1.243\n",
       "12       3.728\n",
       "13       2.083\n",
       "14       1.971\n",
       "15       5.659\n",
       "16       4.652\n",
       "17      35.461\n",
       "18       1.320\n",
       "19       3.509\n",
       "20       3.833\n",
       "21       2.569\n",
       "22       4.857\n",
       "23       1.131\n",
       "24       5.466\n",
       "25       2.565\n",
       "26       5.466\n",
       "27       2.611\n",
       "28       4.000\n",
       "29       2.687\n",
       "         ...  \n",
       "4571     1.256\n",
       "4572     1.000\n",
       "4573     1.489\n",
       "4574     1.220\n",
       "4575     1.720\n",
       "4576     1.488\n",
       "4577     1.200\n",
       "4578     1.372\n",
       "4579     3.766\n",
       "4580     1.571\n",
       "4581     1.586\n",
       "4582     1.266\n",
       "4583     1.666\n",
       "4584     1.500\n",
       "4585     1.375\n",
       "4586     1.793\n",
       "4587     1.272\n",
       "4588     1.111\n",
       "4589     1.000\n",
       "4590     2.468\n",
       "4591     1.000\n",
       "4592     1.285\n",
       "4593     1.000\n",
       "4594     1.727\n",
       "4595     1.000\n",
       "4596     1.142\n",
       "4597     1.555\n",
       "4598     1.404\n",
       "4599     1.147\n",
       "4600     1.250\n",
       "Name: 54, Length: 4601, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(filepath_or_buffer='spambase/spambase.data', header = None)\n",
    "inputs_indx = [x for x in range(57)]\n",
    "label_indx = 57\n",
    "print(len(dataset))\n",
    "dataset.drop_duplicates()\n",
    "print(len(dataset))\n",
    "dataset[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "dataset.loc[:, inputs_indx] = scaler.fit_transform(dataset.loc[:, inputs_indx])\n",
    "print(len(scaler.mean_))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.hist(dataset[i], bins = 15)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('hist1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.hist(dataset[i + 25], bins = 15)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('hist2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.hist(dataset[i + 50], bins = 15)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('hist3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset[i], vert=False)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset[i + 25], vert=False)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.boxplot(dataset[i + 50], vert=False)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('box3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset[dataset[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset[dataset[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset[dataset[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset[dataset[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_of_dataset = np.array(dataset.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_of_dataset = np.array(dataset.corr(method='spearman'))\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(spearman_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(spearman_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_spearman.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendal_of_dataset = np.array(dataset.corr(method='kendall'))\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(kendal_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(kendal_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_kendal.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [32, 51], [44, 52], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 56], [37, 55], [44, 43], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33], [54, 55]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    plt.scatter(dataset[atr_to_scatter[i][0]], dataset[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.OneClassSVM(kernel=\"rbf\")\n",
    "clf.fit(dataset[inputs_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIER_FRACTION = 0.05\n",
    "dist_to_border = clf.decision_function(dataset[inputs_indx]).ravel()\n",
    "threshold = stats.scoreatpercentile(dist_to_border,\n",
    "            100 * OUTLIER_FRACTION)\n",
    "is_inlier = dist_to_border > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([177.,  12.,   6.,   5.,   6.,   4.,   1.,   5.,   3.,   1.,   3.,\n",
       "          4.,   1.,   2.,   1.]),\n",
       " array([-6.3928493 , -6.39156876, -6.39028822, -6.38900768, -6.38772714,\n",
       "        -6.3864466 , -6.38516607, -6.38388553, -6.38260499, -6.38132445,\n",
       "        -6.38004391, -6.37876337, -6.37748283, -6.37620229, -6.37492175,\n",
       "        -6.37364121]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e7a7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dist_to_border[is_inlier == False], bins = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.01\n",
      "4554.99\n",
      "231\n",
      "4370\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...   48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.0  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.0  0.132   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.0  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.0  0.135   \n",
       "5  0.00  0.00  0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00 ...  0.0  0.223   \n",
       "\n",
       "    50     51    52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.00  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.18  0.048  5.114  101  1028   1  \n",
       "3  0.0  0.137  0.00  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.00  0.000  3.537   40   191   1  \n",
       "5  0.0  0.000  0.00  0.000  3.000   15    54   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_outlier = dataset[is_inlier == False]\n",
    "dataset_clear = dataset[is_inlier == True]\n",
    "print(len(dataset)*0.01)\n",
    "print(len(dataset)*0.99)\n",
    "print(len(dataset_outlier))\n",
    "print(len(dataset_clear))\n",
    "dataset_clear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset_clear[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('after_svm_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset_clear[i], vert=False)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset_clear[i + 25], vert=False)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.boxplot(dataset_clear[i + 50], vert=False)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('box3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset_clear[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('after_svm_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.028886</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.029985</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.075075</td>\n",
       "      <td>0.112994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3      4         5         6         7   \\\n",
       "0  0.000000  0.044818  0.125490  0.0  0.032  0.000000  0.000000  0.000000   \n",
       "1  0.046256  0.019608  0.098039  0.0  0.014  0.047619  0.028886  0.006301   \n",
       "3  0.000000  0.000000  0.000000  0.0  0.063  0.000000  0.042641  0.056706   \n",
       "4  0.000000  0.000000  0.000000  0.0  0.063  0.000000  0.042641  0.056706   \n",
       "5  0.000000  0.000000  0.000000  0.0  0.185  0.000000  0.000000  0.166517   \n",
       "\n",
       "         8         9  ...   48        49   50        51        52        53  \\\n",
       "0  0.000000  0.000000 ...  0.0  0.000000  0.0  0.081253  0.000000  0.000000   \n",
       "1  0.000000  0.084608 ...  0.0  0.025014  0.0  0.038851  0.029985  0.003656   \n",
       "3  0.058935  0.056706 ...  0.0  0.025962  0.0  0.014308  0.000000  0.000000   \n",
       "4  0.058935  0.056706 ...  0.0  0.025583  0.0  0.014099  0.000000  0.000000   \n",
       "5  0.000000  0.000000 ...  0.0  0.042259  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "         54        55        56  57  \n",
       "0  0.004138  0.045045  0.030476   1  \n",
       "1  0.006177  0.075075  0.112994   1  \n",
       "3  0.003809  0.029279  0.020904   1  \n",
       "4  0.003809  0.029279  0.020904   1  \n",
       "5  0.003003  0.010511  0.005831   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clear.loc[:, inputs_indx] = preprocessing.minmax_scale(dataset_clear.loc[:, inputs_indx])\n",
    "dataset_clear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4370 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "0     4370 non-null float64\n",
      "1     4370 non-null float64\n",
      "2     4370 non-null float64\n",
      "3     4370 non-null float64\n",
      "4     4370 non-null float64\n",
      "5     4370 non-null float64\n",
      "6     4370 non-null float64\n",
      "7     4370 non-null float64\n",
      "8     4370 non-null float64\n",
      "9     4370 non-null float64\n",
      "10    4370 non-null float64\n",
      "11    4370 non-null float64\n",
      "12    4370 non-null float64\n",
      "13    4370 non-null float64\n",
      "14    4370 non-null float64\n",
      "15    4370 non-null float64\n",
      "16    4370 non-null float64\n",
      "17    4370 non-null float64\n",
      "18    4370 non-null float64\n",
      "19    4370 non-null float64\n",
      "20    4370 non-null float64\n",
      "21    4370 non-null float64\n",
      "22    4370 non-null float64\n",
      "23    4370 non-null float64\n",
      "24    4370 non-null float64\n",
      "25    4370 non-null float64\n",
      "26    4370 non-null float64\n",
      "27    4370 non-null float64\n",
      "28    4370 non-null float64\n",
      "29    4370 non-null float64\n",
      "30    4370 non-null float64\n",
      "31    4370 non-null float64\n",
      "32    4370 non-null float64\n",
      "33    4370 non-null float64\n",
      "34    4370 non-null float64\n",
      "35    4370 non-null float64\n",
      "36    4370 non-null float64\n",
      "37    4370 non-null float64\n",
      "38    4370 non-null float64\n",
      "39    4370 non-null float64\n",
      "40    4370 non-null float64\n",
      "41    4370 non-null float64\n",
      "42    4370 non-null float64\n",
      "43    4370 non-null float64\n",
      "44    4370 non-null float64\n",
      "45    4370 non-null float64\n",
      "46    4370 non-null float64\n",
      "47    4370 non-null float64\n",
      "48    4370 non-null float64\n",
      "49    4370 non-null float64\n",
      "50    4370 non-null float64\n",
      "51    4370 non-null float64\n",
      "52    4370 non-null float64\n",
      "53    4370 non-null float64\n",
      "54    4370 non-null float64\n",
      "55    4370 non-null float64\n",
      "56    4370 non-null float64\n",
      "57    4370 non-null int64\n",
      "dtypes: float64(57), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_clear.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset_clear[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('scale_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset_clear[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('scale_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [32, 51], [44, 52], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 56], [37, 55], [44, 43], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33], [54, 55]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    plt.scatter(dataset_clear[atr_to_scatter[i][0]], dataset_clear[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('scale_scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_of_dataset_clear = np.array(dataset_clear.corr())\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_of_dataset_clear)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_of_dataset_clear, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr_clear.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_dataset = PCA(n_components=50).fit_transform(dataset_clear[inputs_indx])\n",
    "end_dataset = pd.DataFrame(end_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_features = features.corr()\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_features)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_features, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr_features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4370 entries, 0 to 4369\n",
      "Data columns (total 51 columns):\n",
      "0     4370 non-null float64\n",
      "1     4370 non-null float64\n",
      "2     4370 non-null float64\n",
      "3     4370 non-null float64\n",
      "4     4370 non-null float64\n",
      "5     4370 non-null float64\n",
      "6     4370 non-null float64\n",
      "7     4370 non-null float64\n",
      "8     4370 non-null float64\n",
      "9     4370 non-null float64\n",
      "10    4370 non-null float64\n",
      "11    4370 non-null float64\n",
      "12    4370 non-null float64\n",
      "13    4370 non-null float64\n",
      "14    4370 non-null float64\n",
      "15    4370 non-null float64\n",
      "16    4370 non-null float64\n",
      "17    4370 non-null float64\n",
      "18    4370 non-null float64\n",
      "19    4370 non-null float64\n",
      "20    4370 non-null float64\n",
      "21    4370 non-null float64\n",
      "22    4370 non-null float64\n",
      "23    4370 non-null float64\n",
      "24    4370 non-null float64\n",
      "25    4370 non-null float64\n",
      "26    4370 non-null float64\n",
      "27    4370 non-null float64\n",
      "28    4370 non-null float64\n",
      "29    4370 non-null float64\n",
      "30    4370 non-null float64\n",
      "31    4370 non-null float64\n",
      "32    4370 non-null float64\n",
      "33    4370 non-null float64\n",
      "34    4370 non-null float64\n",
      "35    4370 non-null float64\n",
      "36    4370 non-null float64\n",
      "37    4370 non-null float64\n",
      "38    4370 non-null float64\n",
      "39    4370 non-null float64\n",
      "40    4370 non-null float64\n",
      "41    4370 non-null float64\n",
      "42    4370 non-null float64\n",
      "43    4370 non-null float64\n",
      "44    4370 non-null float64\n",
      "45    4370 non-null float64\n",
      "46    4370 non-null float64\n",
      "47    4370 non-null float64\n",
      "48    4370 non-null float64\n",
      "49    4370 non-null float64\n",
      "50    4370 non-null int64\n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "end_dataset[50] = np.array(dataset_clear[57])\n",
    "end_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(features[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((features[labels == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((features[labels == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('end_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(features[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((features[labels == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((features[labels == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('end_scale_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [44, 45], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 16], [37, 35], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.scatter(features[atr_to_scatter[i][0]], features[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('end_scale_scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonspam_end_dataset = end_dataset[end_dataset[50] == 0]\n",
    "spam_end_dataset = end_dataset[end_dataset[50] == 1]\n",
    "nonspam_end_dataset = nonspam_end_dataset.reindex()\n",
    "spam_end_dataset= spam_end_dataset.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621 1311 438 4370 4370\n"
     ]
    }
   ],
   "source": [
    "rand_indxs_spam = np.arange(len(spam_end_dataset))\n",
    "rand_indxs_nonspam = np.arange(len(nonspam_end_dataset))\n",
    "\n",
    "np.random.shuffle(rand_indxs_spam)\n",
    "np.random.shuffle(rand_indxs_nonspam)\n",
    "\n",
    "f_threshold_spam = int(len(spam_end_dataset)*0.6)\n",
    "s_threshold_spam = int(len(spam_end_dataset)*0.9)\n",
    "\n",
    "f_threshold_nonspam = int(len(nonspam_end_dataset)*0.6)\n",
    "s_threshold_nonspam = int(len(nonspam_end_dataset)*0.9)\n",
    "\n",
    "learn_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[:f_threshold_spam]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[:f_threshold_nonspam]]])\n",
    "\n",
    "valid_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[f_threshold_spam:s_threshold_spam]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[f_threshold_nonspam:s_threshold_nonspam]]])\n",
    "\n",
    "test_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[s_threshold_spam:]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[s_threshold_nonspam:]]])\n",
    "\n",
    "print(len(learn_dataset), len(valid_dataset), len(test_dataset), len(learn_dataset)+len(valid_dataset)+len(test_dataset), len(end_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 438 entries, 192 to 1775\n",
      "Data columns (total 51 columns):\n",
      "0     438 non-null float64\n",
      "1     438 non-null float64\n",
      "2     438 non-null float64\n",
      "3     438 non-null float64\n",
      "4     438 non-null float64\n",
      "5     438 non-null float64\n",
      "6     438 non-null float64\n",
      "7     438 non-null float64\n",
      "8     438 non-null float64\n",
      "9     438 non-null float64\n",
      "10    438 non-null float64\n",
      "11    438 non-null float64\n",
      "12    438 non-null float64\n",
      "13    438 non-null float64\n",
      "14    438 non-null float64\n",
      "15    438 non-null float64\n",
      "16    438 non-null float64\n",
      "17    438 non-null float64\n",
      "18    438 non-null float64\n",
      "19    438 non-null float64\n",
      "20    438 non-null float64\n",
      "21    438 non-null float64\n",
      "22    438 non-null float64\n",
      "23    438 non-null float64\n",
      "24    438 non-null float64\n",
      "25    438 non-null float64\n",
      "26    438 non-null float64\n",
      "27    438 non-null float64\n",
      "28    438 non-null float64\n",
      "29    438 non-null float64\n",
      "30    438 non-null float64\n",
      "31    438 non-null float64\n",
      "32    438 non-null float64\n",
      "33    438 non-null float64\n",
      "34    438 non-null float64\n",
      "35    438 non-null float64\n",
      "36    438 non-null float64\n",
      "37    438 non-null float64\n",
      "38    438 non-null float64\n",
      "39    438 non-null float64\n",
      "40    438 non-null float64\n",
      "41    438 non-null float64\n",
      "42    438 non-null float64\n",
      "43    438 non-null float64\n",
      "44    438 non-null float64\n",
      "45    438 non-null float64\n",
      "46    438 non-null float64\n",
      "47    438 non-null float64\n",
      "48    438 non-null float64\n",
      "49    438 non-null float64\n",
      "50    438 non-null int64\n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 177.9 KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_spam_data = np.array(MyDataset(learn_dataset))\n",
    "valid_spam_data = np.array(MyDataset(valid_dataset))\n",
    "test_spam_data = np.array(MyDataset(test_dataset))\n",
    "learn_dataloader = DataLoader(learn_spam_data, batch_size=1, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_spam_data, batch_size=len(valid_spam_data), shuffle=False)\n",
    "test_dataloader = DataLoader(test_spam_data, batch_size=len(test_spam_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2621, 51)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_spam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lin3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, 20)\n",
    "        self.lin2 = nn.Linear(20, 10)\n",
    "        self.lin3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " -1.5863 -0.1520  1.6800 -0.4292  3.9021  2.5049 -2.6830 -2.1297 -0.6220  0.0988\n",
       " [torch.FloatTensor of size 1x10], \n",
       " \n",
       " Columns 0 to 9 \n",
       "  0.3449  0.1504  0.1065 -0.5611  0.1078  0.0087  0.0637  0.0882 -0.5131  0.3355\n",
       "  0.0392  0.0495  0.0455 -0.2047  0.1758  0.2548 -0.2981 -0.0260  0.1092 -0.2205\n",
       "  0.1925 -0.2825  0.2007  0.0188  0.3427 -0.0554  0.5184  0.1396  0.3375 -0.0684\n",
       " -0.2315 -0.0823 -0.0688 -0.0057 -0.1077  0.1615 -0.0201 -0.0688 -0.0404 -0.3906\n",
       " -0.0432  0.1595  0.4263  0.3102  0.4861  0.0921 -0.1339 -0.4441  0.2341  0.4753\n",
       " -0.3038  0.1272 -0.0907 -0.1099  0.3218  0.1310 -0.1328  0.0560  0.1582  0.2746\n",
       " -0.2597 -0.1334 -0.4258 -0.0162 -0.4272 -0.0034  0.3789  0.2745  0.0859  0.6288\n",
       " -0.1093 -0.0827  0.4269  0.2689  0.0135  0.0223 -0.2033 -0.1155 -0.1953  0.0516\n",
       " -0.1081 -0.1939 -0.2916  0.0188  0.0081 -0.3438  0.1143  0.1347  0.0330  0.0682\n",
       " -0.0447  0.4184  0.0998 -0.0211  0.3387  0.2251  0.0835  0.0306  0.1368 -0.3740\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.1546 -0.1310 -0.1458 -0.2107 -0.1383  0.0111  0.0809 -0.4814 -0.1141  0.4612\n",
       "  0.5705  0.2660 -0.3007 -0.1782  0.2357 -0.1380 -0.0973 -0.2675 -0.4449  0.1883\n",
       "  0.1562 -0.2019  0.0789 -0.0982 -0.2108 -0.1072 -0.1493 -0.0432 -0.6728 -0.6001\n",
       "  0.0026  0.0565  0.1419  0.0798  0.5180  0.1779  0.1534 -0.3517  0.2617 -0.2441\n",
       " -0.0054  0.0005 -0.1748  0.0198 -0.0504 -0.0177 -0.0552  0.1876 -0.3846  0.0686\n",
       "  0.1463  0.0252 -0.0902 -0.4152  0.0216 -0.1909  0.1337 -0.1810  0.1146  0.0967\n",
       " -0.0442  0.1620  0.1505  0.2133 -0.1253 -0.2248  0.0970  0.1379  0.0640 -0.1427\n",
       "  0.1871 -0.2598 -0.5676  0.2593  0.4435  0.2100 -0.2019 -0.0388 -0.3251 -0.0881\n",
       " -0.4366  0.4306  0.2449  0.1917 -0.1798  0.4303 -0.0318 -0.0699  0.0269  0.3886\n",
       " -0.1153 -0.0495 -0.4480 -0.2326  0.1599 -0.3536  0.0420  0.4411 -0.0097  0.3725\n",
       " [torch.FloatTensor of size 10x20], \n",
       " -0.1263 -0.1550  0.1200  ...   0.0290 -0.2502  0.0359\n",
       "  0.0086 -0.1196  0.2093  ...   0.1777 -0.0097  0.0987\n",
       "  0.1033 -0.0040  0.3408  ...  -0.2071 -0.1949  0.1650\n",
       "           ...             ⋱             ...          \n",
       " -0.1982  0.1295  0.2638  ...   0.1068 -0.1714 -0.0684\n",
       "  0.1017  0.1597 -0.0554  ...  -0.2044  0.2460  0.0145\n",
       "  0.2744  0.0626  0.1037  ...   0.1227  0.0397 -0.0994\n",
       " [torch.FloatTensor of size 20x50]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Инициализация весов\n",
    "stds = [(2/(50+20+1))**(1/2), (2/(20+10+1))**(1/2), (32/(10+1+1))**(1/2)]\n",
    "null_weigth = []\n",
    "stds.reverse()\n",
    "def get_weights(layer):\n",
    "    if (type(layer) == nn.Linear):\n",
    "        null_weigth.append(torch.randn(layer.weight.data.shape)*stds.pop())\n",
    "net.apply(get_weights)\n",
    "null_weigth.reverse()\n",
    "null_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.3449  0.1504  0.1065 -0.5611  0.1078  0.0087  0.0637  0.0882 -0.5131  0.3355\n",
       " 0.0392  0.0495  0.0455 -0.2047  0.1758  0.2548 -0.2981 -0.0260  0.1092 -0.2205\n",
       " 0.1925 -0.2825  0.2007  0.0188  0.3427 -0.0554  0.5184  0.1396  0.3375 -0.0684\n",
       "-0.2315 -0.0823 -0.0688 -0.0057 -0.1077  0.1615 -0.0201 -0.0688 -0.0404 -0.3906\n",
       "-0.0432  0.1595  0.4263  0.3102  0.4861  0.0921 -0.1339 -0.4441  0.2341  0.4753\n",
       "-0.3038  0.1272 -0.0907 -0.1099  0.3218  0.1310 -0.1328  0.0560  0.1582  0.2746\n",
       "-0.2597 -0.1334 -0.4258 -0.0162 -0.4272 -0.0034  0.3789  0.2745  0.0859  0.6288\n",
       "-0.1093 -0.0827  0.4269  0.2689  0.0135  0.0223 -0.2033 -0.1155 -0.1953  0.0516\n",
       "-0.1081 -0.1939 -0.2916  0.0188  0.0081 -0.3438  0.1143  0.1347  0.0330  0.0682\n",
       "-0.0447  0.4184  0.0998 -0.0211  0.3387  0.2251  0.0835  0.0306  0.1368 -0.3740\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.1546 -0.1310 -0.1458 -0.2107 -0.1383  0.0111  0.0809 -0.4814 -0.1141  0.4612\n",
       " 0.5705  0.2660 -0.3007 -0.1782  0.2357 -0.1380 -0.0973 -0.2675 -0.4449  0.1883\n",
       " 0.1562 -0.2019  0.0789 -0.0982 -0.2108 -0.1072 -0.1493 -0.0432 -0.6728 -0.6001\n",
       " 0.0026  0.0565  0.1419  0.0798  0.5180  0.1779  0.1534 -0.3517  0.2617 -0.2441\n",
       "-0.0054  0.0005 -0.1748  0.0198 -0.0504 -0.0177 -0.0552  0.1876 -0.3846  0.0686\n",
       " 0.1463  0.0252 -0.0902 -0.4152  0.0216 -0.1909  0.1337 -0.1810  0.1146  0.0967\n",
       "-0.0442  0.1620  0.1505  0.2133 -0.1253 -0.2248  0.0970  0.1379  0.0640 -0.1427\n",
       " 0.1871 -0.2598 -0.5676  0.2593  0.4435  0.2100 -0.2019 -0.0388 -0.3251 -0.0881\n",
       "-0.4366  0.4306  0.2449  0.1917 -0.1798  0.4303 -0.0318 -0.0699  0.0269  0.3886\n",
       "-0.1153 -0.0495 -0.4480 -0.2326  0.1599 -0.3536  0.0420  0.4411 -0.0097  0.3725\n",
       "[torch.FloatTensor of size 10x20]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_null_weigth = null_weigth.copy()\n",
    "def init_weigths(layer):\n",
    "    if(type(layer) == nn.Linear):\n",
    "        layer.weight.data = tmp_null_weigth.pop()\n",
    "net.apply(init_weigths)\n",
    "net.lin2.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(size_average=True)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = np.arange(50)\n",
    "feature_index\n",
    "label_indx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([1311])) that is different to the input size (torch.Size([1311, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7104\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for valid_data in valid_dataloader:\n",
    "        features_valid, labels_valid = valid_data[:, feature_index], valid_data[:, label_indx]\n",
    "        features_valid, labels_valid  = autograd.Variable(features_valid).float(), autograd.Variable(labels_valid).float()\n",
    "        outputs_valid = net(features_valid)\n",
    "        loss = criterion(outputs_valid, labels_valid)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index\n",
    "learn_epoch_loss = []\n",
    "for epoch in range(1):#10**5:\n",
    "    loss_acc = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    for learn_data in learn_dataloader:\n",
    "        features_learn, labels_learn = learn_data[:, feature_index], learn_data[:, label_indx]\n",
    "        features_learn, labels_learn  = autograd.Variable((features_learn).float()).unsqueeze(1), autograd.Variable(torch.from_numpy(labels_learn).float()).unsqueeze(1)\n",
    "        outputs_learn = net(features_learn)\n",
    "        loss_learn = criterion(outputs_learn, labels_learn)\n",
    "        loss_learn.backward()\n",
    "        optimizer.step()\n",
    "        loss_acc += float(loss_learn.data)\n",
    "        \n",
    "        \n",
    "    learn_epoch_loss.append(loss_acc/len(learn_dataloader))\n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.plot(err_epoh, color='r') \n",
    "    plt.plot(valid_err_epoh, color='b') \n",
    "    plt.plot(test_err_epoh, color='g') \n",
    "\n",
    "    display.clear_output(wait=True) \n",
    "    display.display(plt.gcf()) \n",
    "\n",
    "    print(epoch, end=\" \")\n",
    "        \n",
    "    learn_epoh_loss.append(loss_acc)\n",
    "    \n",
    "plt.plot(learn_epoh_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta_weight = 10\n",
    "#while delta_weight > np.exp(-5):\n",
    "#    for data in learn_dataloader:\n",
    "#        features, labels = data[inputs_indx], data[57]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
