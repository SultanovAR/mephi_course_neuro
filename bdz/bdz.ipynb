{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.autograd as autograd\n",
    "from torch import optim\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "4601\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(filepath_or_buffer='spambase/spambase.data', header = None)\n",
    "inputs_indx = [x for x in range(57)]\n",
    "label_indx = 57\n",
    "print(len(dataset))\n",
    "dataset.drop_duplicates()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "dataset.loc[:, inputs_indx] = scaler.fit_transform(dataset.loc[:, inputs_indx])\n",
    "print(len(scaler.mean_))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.hist(dataset[i], bins = 15)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('hist1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.hist(dataset[i + 25], bins = 15)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('hist2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.hist(dataset[i + 50], bins = 15)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('hist3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset[i], vert=False)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset[i + 25], vert=False)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.boxplot(dataset[i + 50], vert=False)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('box3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset[dataset[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset[dataset[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset[dataset[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset[dataset[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_of_dataset = np.array(dataset.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spearman_of_dataset = np.array(dataset.corr(method='spearman'))\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(spearman_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(spearman_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_spearman.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kendal_of_dataset = np.array(dataset.corr(method='kendall'))\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(kendal_of_dataset)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(kendal_of_dataset, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_kendal.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [32, 51], [44, 52], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 56], [37, 55], [44, 43], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33], [54, 55]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    plt.scatter(dataset[atr_to_scatter[i][0]], dataset[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.OneClassSVM(kernel=\"rbf\")\n",
    "clf.fit(dataset[inputs_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIER_FRACTION = 0.05\n",
    "dist_to_border = clf.decision_function(dataset[inputs_indx]).ravel()\n",
    "threshold = stats.scoreatpercentile(dist_to_border,\n",
    "            100 * OUTLIER_FRACTION)\n",
    "is_inlier = dist_to_border > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([177.,  12.,   6.,   5.,   6.,   4.,   1.,   5.,   3.,   1.,   3.,\n",
       "          4.,   1.,   2.,   1.]),\n",
       " array([-6.3928493 , -6.39156876, -6.39028822, -6.38900768, -6.38772714,\n",
       "        -6.3864466 , -6.38516607, -6.38388553, -6.38260499, -6.38132445,\n",
       "        -6.38004391, -6.37876337, -6.37748283, -6.37620229, -6.37492175,\n",
       "        -6.37364121]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a4e50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dist_to_border[is_inlier == False], bins = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230.05\n",
      "4370.95\n",
      "231\n",
      "4370\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...   48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.0  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.0  0.132   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.0  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.0  0.135   \n",
       "5  0.00  0.00  0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00 ...  0.0  0.223   \n",
       "\n",
       "    50     51    52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.00  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.18  0.048  5.114  101  1028   1  \n",
       "3  0.0  0.137  0.00  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.00  0.000  3.537   40   191   1  \n",
       "5  0.0  0.000  0.00  0.000  3.000   15    54   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_outlier = dataset[is_inlier == False]\n",
    "dataset_clear = dataset[is_inlier == True]\n",
    "print(len(dataset)*0.05)\n",
    "print(len(dataset)*0.95)\n",
    "print(len(dataset_outlier))\n",
    "print(len(dataset_clear))\n",
    "dataset_clear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset_clear[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('after_svm_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset_clear[i], vert=False)\n",
    "    plt.title(i+1)\n",
    "plt.savefig('box1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (20, 19))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.boxplot(dataset_clear[i + 25], vert=False)\n",
    "    plt.title(i + 26)\n",
    "plt.savefig('box2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 7))\n",
    "for i in range(7):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.boxplot(dataset_clear[i + 50], vert=False)\n",
    "    plt.title(i + 51)\n",
    "plt.savefig('box3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset_clear[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('after_svm_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.028886</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.029985</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.075075</td>\n",
       "      <td>0.112994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3      4         5         6         7   \\\n",
       "0  0.000000  0.044818  0.125490  0.0  0.032  0.000000  0.000000  0.000000   \n",
       "1  0.046256  0.019608  0.098039  0.0  0.014  0.047619  0.028886  0.006301   \n",
       "3  0.000000  0.000000  0.000000  0.0  0.063  0.000000  0.042641  0.056706   \n",
       "4  0.000000  0.000000  0.000000  0.0  0.063  0.000000  0.042641  0.056706   \n",
       "5  0.000000  0.000000  0.000000  0.0  0.185  0.000000  0.000000  0.166517   \n",
       "\n",
       "         8         9  ...   48        49   50        51        52        53  \\\n",
       "0  0.000000  0.000000 ...  0.0  0.000000  0.0  0.081253  0.000000  0.000000   \n",
       "1  0.000000  0.084608 ...  0.0  0.025014  0.0  0.038851  0.029985  0.003656   \n",
       "3  0.058935  0.056706 ...  0.0  0.025962  0.0  0.014308  0.000000  0.000000   \n",
       "4  0.058935  0.056706 ...  0.0  0.025583  0.0  0.014099  0.000000  0.000000   \n",
       "5  0.000000  0.000000 ...  0.0  0.042259  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "         54        55        56  57  \n",
       "0  0.004138  0.045045  0.030476   1  \n",
       "1  0.006177  0.075075  0.112994   1  \n",
       "3  0.003809  0.029279  0.020904   1  \n",
       "4  0.003809  0.029279  0.020904   1  \n",
       "5  0.003003  0.010511  0.005831   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clear.loc[:, inputs_indx] = preprocessing.minmax_scale(dataset_clear.loc[:, inputs_indx])\n",
    "dataset_clear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4370 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "0     4370 non-null float64\n",
      "1     4370 non-null float64\n",
      "2     4370 non-null float64\n",
      "3     4370 non-null float64\n",
      "4     4370 non-null float64\n",
      "5     4370 non-null float64\n",
      "6     4370 non-null float64\n",
      "7     4370 non-null float64\n",
      "8     4370 non-null float64\n",
      "9     4370 non-null float64\n",
      "10    4370 non-null float64\n",
      "11    4370 non-null float64\n",
      "12    4370 non-null float64\n",
      "13    4370 non-null float64\n",
      "14    4370 non-null float64\n",
      "15    4370 non-null float64\n",
      "16    4370 non-null float64\n",
      "17    4370 non-null float64\n",
      "18    4370 non-null float64\n",
      "19    4370 non-null float64\n",
      "20    4370 non-null float64\n",
      "21    4370 non-null float64\n",
      "22    4370 non-null float64\n",
      "23    4370 non-null float64\n",
      "24    4370 non-null float64\n",
      "25    4370 non-null float64\n",
      "26    4370 non-null float64\n",
      "27    4370 non-null float64\n",
      "28    4370 non-null float64\n",
      "29    4370 non-null float64\n",
      "30    4370 non-null float64\n",
      "31    4370 non-null float64\n",
      "32    4370 non-null float64\n",
      "33    4370 non-null float64\n",
      "34    4370 non-null float64\n",
      "35    4370 non-null float64\n",
      "36    4370 non-null float64\n",
      "37    4370 non-null float64\n",
      "38    4370 non-null float64\n",
      "39    4370 non-null float64\n",
      "40    4370 non-null float64\n",
      "41    4370 non-null float64\n",
      "42    4370 non-null float64\n",
      "43    4370 non-null float64\n",
      "44    4370 non-null float64\n",
      "45    4370 non-null float64\n",
      "46    4370 non-null float64\n",
      "47    4370 non-null float64\n",
      "48    4370 non-null float64\n",
      "49    4370 non-null float64\n",
      "50    4370 non-null float64\n",
      "51    4370 non-null float64\n",
      "52    4370 non-null float64\n",
      "53    4370 non-null float64\n",
      "54    4370 non-null float64\n",
      "55    4370 non-null float64\n",
      "56    4370 non-null float64\n",
      "57    4370 non-null int64\n",
      "dtypes: float64(57), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_clear.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(dataset_clear[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((dataset_clear[dataset_clear[57] == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('scale_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(dataset_clear[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((dataset_clear[dataset_clear[57] == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('scale_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [32, 51], [44, 52], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 56], [37, 55], [44, 43], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33], [54, 55]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    plt.scatter(dataset_clear[atr_to_scatter[i][0]], dataset_clear[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('scale_scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_of_dataset_clear = np.array(dataset_clear.corr())\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_of_dataset_clear)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_of_dataset_clear, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr_clear.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_dataset = PCA(n_components=50).fit_transform(dataset_clear[inputs_indx])\n",
    "end_dataset = pd.DataFrame(end_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr_features = features.corr()\n",
    "plt.figure(figsize=(18,11))\n",
    "mask = np.zeros_like(corr_features)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_features, vmin=-1, vmax=1, linewidths=0.1, cmap=\"YlGnBu\", mask=mask)\n",
    "plt.savefig('heat_corr_features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4370 entries, 0 to 4369\n",
      "Data columns (total 51 columns):\n",
      "0     4370 non-null float64\n",
      "1     4370 non-null float64\n",
      "2     4370 non-null float64\n",
      "3     4370 non-null float64\n",
      "4     4370 non-null float64\n",
      "5     4370 non-null float64\n",
      "6     4370 non-null float64\n",
      "7     4370 non-null float64\n",
      "8     4370 non-null float64\n",
      "9     4370 non-null float64\n",
      "10    4370 non-null float64\n",
      "11    4370 non-null float64\n",
      "12    4370 non-null float64\n",
      "13    4370 non-null float64\n",
      "14    4370 non-null float64\n",
      "15    4370 non-null float64\n",
      "16    4370 non-null float64\n",
      "17    4370 non-null float64\n",
      "18    4370 non-null float64\n",
      "19    4370 non-null float64\n",
      "20    4370 non-null float64\n",
      "21    4370 non-null float64\n",
      "22    4370 non-null float64\n",
      "23    4370 non-null float64\n",
      "24    4370 non-null float64\n",
      "25    4370 non-null float64\n",
      "26    4370 non-null float64\n",
      "27    4370 non-null float64\n",
      "28    4370 non-null float64\n",
      "29    4370 non-null float64\n",
      "30    4370 non-null float64\n",
      "31    4370 non-null float64\n",
      "32    4370 non-null float64\n",
      "33    4370 non-null float64\n",
      "34    4370 non-null float64\n",
      "35    4370 non-null float64\n",
      "36    4370 non-null float64\n",
      "37    4370 non-null float64\n",
      "38    4370 non-null float64\n",
      "39    4370 non-null float64\n",
      "40    4370 non-null float64\n",
      "41    4370 non-null float64\n",
      "42    4370 non-null float64\n",
      "43    4370 non-null float64\n",
      "44    4370 non-null float64\n",
      "45    4370 non-null float64\n",
      "46    4370 non-null float64\n",
      "47    4370 non-null float64\n",
      "48    4370 non-null float64\n",
      "49    4370 non-null float64\n",
      "50    4370 non-null int64\n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "end_dataset[50] = np.array(dataset_clear[57])\n",
    "end_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier_list = [6, 8, 31, 35]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(outlier_list) * 3):\n",
    "    plt.subplot(len(outlier_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.boxplot(features[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('gen, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.boxplot((features[labels == 0])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('good, ' + str(outlier_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.boxplot((features[labels == 1])[outlier_list[k] - 1], vert=False)\n",
    "        plt.title('spam, ' + str(outlier_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('end_outlier_goodbad.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respective_list = [2, 12, 19, 21]\n",
    "k = 0\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(respective_list) * 3):\n",
    "    plt.subplot(len(respective_list), 3, i+1)\n",
    "    if (i+1) % 3 == 1:\n",
    "        plt.hist(features[respective_list[k] - 1], bins=15)\n",
    "        plt.title('gen, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 2:\n",
    "        plt.hist((features[labels == 0])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('good, ' + str(respective_list[k]))\n",
    "    if (i+1) % 3 == 0:\n",
    "        plt.hist((features[labels == 1])[respective_list[k] - 1], bins=15)\n",
    "        plt.title('spam, ' + str(respective_list[k]))\n",
    "        k += 1\n",
    "plt.savefig('end_scale_hist_gengoodspam.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atr_to_scatter = [[6, 26], [14, 32], [21, 46], [2, 47], [44, 45], #low corr\n",
    "                  [1, 6], [4, 11], [11, 19], [15, 16], [37, 35], #middle corr\n",
    "                  [25, 27], [25, 34], [27, 34], [30, 33], [32, 33]] #high corr\n",
    "plt.figure(figsize=(23, 10))\n",
    "for i in range(len(atr_to_scatter)):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.scatter(features[atr_to_scatter[i][0]], features[atr_to_scatter[i][1]])\n",
    "    plt.title('x: '+str(atr_to_scatter[i][0])+' y: '+str(atr_to_scatter[i][1]))\n",
    "plt.savefig('end_scale_scatter_diag.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonspam_end_dataset = end_dataset[end_dataset[50] == 0]\n",
    "spam_end_dataset = end_dataset[end_dataset[50] == 1]\n",
    "nonspam_end_dataset = nonspam_end_dataset.reindex()\n",
    "spam_end_dataset= spam_end_dataset.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621 1311 438 4370 4370\n"
     ]
    }
   ],
   "source": [
    "rand_indxs_spam = np.arange(len(spam_end_dataset))\n",
    "rand_indxs_nonspam = np.arange(len(nonspam_end_dataset))\n",
    "\n",
    "np.random.shuffle(rand_indxs_spam)\n",
    "np.random.shuffle(rand_indxs_nonspam)\n",
    "\n",
    "f_threshold_spam = int(len(spam_end_dataset)*0.6)\n",
    "s_threshold_spam = int(len(spam_end_dataset)*0.9)\n",
    "\n",
    "f_threshold_nonspam = int(len(nonspam_end_dataset)*0.6)\n",
    "s_threshold_nonspam = int(len(nonspam_end_dataset)*0.9)\n",
    "\n",
    "learn_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[:f_threshold_spam]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[:f_threshold_nonspam]]])\n",
    "\n",
    "valid_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[f_threshold_spam:s_threshold_spam]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[f_threshold_nonspam:s_threshold_nonspam]]])\n",
    "\n",
    "test_dataset = pd.concat([spam_end_dataset.iloc[rand_indxs_spam[s_threshold_spam:]],\n",
    "                          nonspam_end_dataset.iloc[rand_indxs_nonspam[s_threshold_nonspam:]]])\n",
    "\n",
    "print(len(learn_dataset), len(valid_dataset), len(test_dataset), len(learn_dataset)+len(valid_dataset)+len(test_dataset), len(end_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 438 entries, 1035 to 3239\n",
      "Data columns (total 51 columns):\n",
      "0     438 non-null float64\n",
      "1     438 non-null float64\n",
      "2     438 non-null float64\n",
      "3     438 non-null float64\n",
      "4     438 non-null float64\n",
      "5     438 non-null float64\n",
      "6     438 non-null float64\n",
      "7     438 non-null float64\n",
      "8     438 non-null float64\n",
      "9     438 non-null float64\n",
      "10    438 non-null float64\n",
      "11    438 non-null float64\n",
      "12    438 non-null float64\n",
      "13    438 non-null float64\n",
      "14    438 non-null float64\n",
      "15    438 non-null float64\n",
      "16    438 non-null float64\n",
      "17    438 non-null float64\n",
      "18    438 non-null float64\n",
      "19    438 non-null float64\n",
      "20    438 non-null float64\n",
      "21    438 non-null float64\n",
      "22    438 non-null float64\n",
      "23    438 non-null float64\n",
      "24    438 non-null float64\n",
      "25    438 non-null float64\n",
      "26    438 non-null float64\n",
      "27    438 non-null float64\n",
      "28    438 non-null float64\n",
      "29    438 non-null float64\n",
      "30    438 non-null float64\n",
      "31    438 non-null float64\n",
      "32    438 non-null float64\n",
      "33    438 non-null float64\n",
      "34    438 non-null float64\n",
      "35    438 non-null float64\n",
      "36    438 non-null float64\n",
      "37    438 non-null float64\n",
      "38    438 non-null float64\n",
      "39    438 non-null float64\n",
      "40    438 non-null float64\n",
      "41    438 non-null float64\n",
      "42    438 non-null float64\n",
      "43    438 non-null float64\n",
      "44    438 non-null float64\n",
      "45    438 non-null float64\n",
      "46    438 non-null float64\n",
      "47    438 non-null float64\n",
      "48    438 non-null float64\n",
      "49    438 non-null float64\n",
      "50    438 non-null int64\n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 177.9 KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_spam_data = np.array(MyDataset(learn_dataset))\n",
    "valid_spam_data = np.array(MyDataset(valid_dataset))\n",
    "test_spam_data = np.array(MyDataset(test_dataset))\n",
    "learn_dataloader = DataLoader(learn_spam_data, batch_size=1, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_spam_data, batch_size=len(valid_spam_data), shuffle=False)\n",
    "test_dataloader = DataLoader(test_spam_data, batch_size=len(test_spam_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2621, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_spam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lin3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(50, 20)\n",
    "        self.lin2 = nn.Linear(20, 10)\n",
    "        self.lin3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.lin1(x))\n",
    "        x = F.tanh(self.lin2(x))\n",
    "        x = F.sigmoid(self.lin3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = np.arange(50)\n",
    "feature_index\n",
    "label_indx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (lin3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def type_weights(layer):\n",
    "    if (type(layer) == nn.Linear):\n",
    "        print(layer.weight.requires_grad)\n",
    "net.apply(type_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.4017, -1.0879, -1.7512, -2.8377,  0.9816,  4.0767,  0.5937,\n",
       "           1.7016,  0.1822,  3.1595]]),\n",
       " tensor([[-0.1180, -0.2621, -0.1991, -0.0667, -0.0699,  0.3183, -0.1767,\n",
       "           0.1941, -0.1084,  0.5431, -0.6486, -0.4177,  0.2071, -0.6020,\n",
       "          -0.2735, -0.2777, -0.2576,  0.6358,  0.1327,  0.0578],\n",
       "         [ 0.4979,  0.0154,  0.1371,  0.3511,  0.3221,  0.2938, -0.1824,\n",
       "          -0.1747, -0.4835,  0.0038,  0.3073,  0.4390, -0.3305,  0.1972,\n",
       "           0.0971, -0.1403,  0.0414, -0.0896,  0.2634,  0.1332],\n",
       "         [ 0.0859,  0.2628,  0.5003, -0.3693, -0.0431,  0.1347, -0.0806,\n",
       "          -0.0341,  0.1608,  0.1136,  0.1328, -0.3166, -0.0097, -0.0500,\n",
       "           0.2682,  0.0436,  0.0841,  0.2857,  0.1577, -0.0825],\n",
       "         [ 0.1440, -0.3311, -0.2155,  0.1750,  0.2173,  0.2960, -0.0980,\n",
       "           0.2638, -0.1894,  0.4184, -0.4635, -0.0099, -0.1411,  0.2375,\n",
       "           0.2912, -0.2412, -0.0351, -0.3142, -0.0382, -0.2894],\n",
       "         [ 0.2244,  0.3405, -0.1454, -0.0260,  0.5738, -0.1113, -0.2169,\n",
       "           0.2583, -0.0056, -0.0338, -0.1040,  0.1247, -0.1456, -0.1237,\n",
       "          -0.1708, -0.0172, -0.5981, -0.3316, -0.0832, -0.0207],\n",
       "         [-0.0917, -0.1143, -0.1143, -0.2198, -0.2752, -0.0874, -0.0861,\n",
       "           0.3804,  0.4554,  0.1875,  0.1078, -0.0517,  0.2266,  0.1596,\n",
       "           0.0392, -0.1379, -0.2045,  0.1806,  0.2403,  0.0971],\n",
       "         [ 0.7047, -0.3632, -0.2746,  0.0184, -0.0818, -0.5050,  0.2554,\n",
       "           0.5009,  0.2650, -0.2433,  0.0365,  0.3569,  0.0126,  0.0106,\n",
       "           0.4862,  0.3043,  0.0738,  0.2269,  0.4228,  0.2343],\n",
       "         [ 0.2683,  0.3039,  0.5243,  0.0139, -0.0731, -0.3667,  0.0617,\n",
       "           0.0407, -0.3594, -0.2747, -0.3058,  0.0045, -0.1007, -0.3311,\n",
       "          -0.0046, -0.0466, -0.0712, -0.0576,  0.3189, -0.1696],\n",
       "         [ 0.1155, -0.1984, -0.2247, -0.2917,  0.1461,  0.0232, -0.2085,\n",
       "          -0.0715, -0.1587, -0.5941,  0.0495,  0.1253,  0.0168, -0.2517,\n",
       "          -0.1978,  0.2629,  0.1932,  0.0104,  0.0192, -0.0893],\n",
       "         [ 0.2660, -0.0181, -0.1150,  0.1092, -0.2797, -0.3922, -0.0365,\n",
       "          -0.6403, -0.2733, -0.1518,  0.1770, -0.1325,  0.0624,  0.1430,\n",
       "          -0.2876, -0.0940,  0.0575,  0.0523,  0.1535,  0.4889]]),\n",
       " tensor([[-0.2052, -0.0789,  0.1123,  0.1124, -0.1954,  0.2992,  0.0019,\n",
       "          -0.2939,  0.0248, -0.0246, -0.1668,  0.1194,  0.0985, -0.1863,\n",
       "           0.2393,  0.0206, -0.0792,  0.1235, -0.0230, -0.0374, -0.0653,\n",
       "           0.0612, -0.0397,  0.0217,  0.0894,  0.0254,  0.0331, -0.0915,\n",
       "           0.0526,  0.1059,  0.3354, -0.0838, -0.3808,  0.0284,  0.0278,\n",
       "          -0.2503, -0.0306, -0.0139,  0.1480, -0.2482, -0.0627,  0.0994,\n",
       "           0.2355,  0.1425,  0.0265,  0.0215,  0.1888, -0.1843, -0.1207,\n",
       "          -0.0592],\n",
       "         [-0.0343, -0.0596,  0.2441, -0.2272, -0.1577, -0.0089, -0.0595,\n",
       "           0.3932, -0.1417, -0.1779, -0.5193,  0.0931,  0.0051,  0.0460,\n",
       "          -0.1526, -0.1373, -0.0103, -0.2703,  0.3219,  0.0835, -0.0962,\n",
       "           0.0525, -0.0550, -0.0710, -0.0688,  0.0733,  0.2397,  0.5199,\n",
       "          -0.1474,  0.0171,  0.0496, -0.3020, -0.0857,  0.2216,  0.1914,\n",
       "           0.0287, -0.1216, -0.0343, -0.0297,  0.0422,  0.1210, -0.0069,\n",
       "          -0.0023, -0.1794, -0.0141,  0.0202,  0.2209,  0.1922,  0.0602,\n",
       "          -0.0533],\n",
       "         [ 0.0430, -0.0172,  0.0348, -0.2969,  0.2011, -0.0547,  0.0044,\n",
       "           0.2071,  0.0887, -0.1242,  0.0328, -0.0148, -0.1567, -0.1687,\n",
       "          -0.0134, -0.1185, -0.0908,  0.2247, -0.2451, -0.0167,  0.1286,\n",
       "           0.0288, -0.4806, -0.0182, -0.0605,  0.3282, -0.2176,  0.1449,\n",
       "          -0.1552,  0.1061,  0.2737, -0.3345, -0.0714,  0.0216, -0.2670,\n",
       "           0.2345,  0.1858, -0.2442,  0.1666, -0.2294, -0.0006,  0.1044,\n",
       "          -0.0604,  0.1154, -0.0150,  0.2563,  0.2176, -0.0364, -0.0918,\n",
       "           0.1318],\n",
       "         [-0.1290,  0.0060,  0.0831, -0.0258,  0.0473, -0.0641,  0.1253,\n",
       "           0.0560, -0.0612,  0.1113, -0.3277, -0.0373, -0.1364, -0.1741,\n",
       "           0.2939,  0.2704,  0.1848, -0.2889, -0.1001,  0.0244,  0.0329,\n",
       "          -0.1453,  0.1227,  0.0689,  0.1994, -0.0634,  0.0026,  0.0486,\n",
       "           0.2301,  0.0846,  0.1333, -0.0362,  0.0708,  0.0350, -0.0639,\n",
       "           0.0670,  0.2704, -0.0816, -0.1676,  0.2262,  0.0330,  0.2398,\n",
       "          -0.1969, -0.0600,  0.0529,  0.1140, -0.1684,  0.1300,  0.0407,\n",
       "          -0.3400],\n",
       "         [-0.0573, -0.1601,  0.0786, -0.1721, -0.2765, -0.0809, -0.0181,\n",
       "           0.0766,  0.0189,  0.1270, -0.1347,  0.0814,  0.4426,  0.0091,\n",
       "           0.0452,  0.1369,  0.0494,  0.0130,  0.0147,  0.0280, -0.0699,\n",
       "          -0.1743,  0.0412,  0.0214, -0.0216,  0.1062, -0.0151,  0.1579,\n",
       "           0.2957,  0.2156,  0.2211, -0.1223, -0.3446,  0.1060, -0.0961,\n",
       "          -0.0077, -0.2081,  0.0744, -0.0048, -0.0770,  0.0395, -0.0099,\n",
       "           0.1546,  0.0972, -0.1357,  0.0650,  0.0064,  0.0221,  0.1912,\n",
       "          -0.0567],\n",
       "         [-0.1708, -0.0667,  0.2652,  0.1400,  0.1204,  0.4062,  0.1786,\n",
       "          -0.0041, -0.1690,  0.0996,  0.0049, -0.0238, -0.1120, -0.2227,\n",
       "          -0.1221,  0.0952, -0.3174, -0.0848, -0.0593,  0.1471,  0.1458,\n",
       "          -0.0330, -0.1080, -0.0831,  0.0490,  0.2326,  0.0879,  0.0201,\n",
       "          -0.0435, -0.1758,  0.0319, -0.1110,  0.0064, -0.0249,  0.0622,\n",
       "          -0.0134,  0.1541,  0.0094,  0.1555, -0.1418, -0.2769, -0.1203,\n",
       "          -0.2225,  0.1036, -0.0354,  0.0333, -0.1291,  0.0511, -0.0357,\n",
       "          -0.1850],\n",
       "         [ 0.2427, -0.1536, -0.0515, -0.0214, -0.1650,  0.0654,  0.2070,\n",
       "          -0.0368,  0.1728, -0.1561,  0.0157,  0.0661, -0.0601,  0.1176,\n",
       "          -0.2020, -0.1312,  0.0433,  0.0591, -0.1969,  0.0725, -0.1008,\n",
       "          -0.0436, -0.1123, -0.0023,  0.0731,  0.0015, -0.3413, -0.1405,\n",
       "           0.1029, -0.3109,  0.2448, -0.1996, -0.2604,  0.2660, -0.0985,\n",
       "           0.0354,  0.1237,  0.3059,  0.1885, -0.0839,  0.1700,  0.0197,\n",
       "          -0.2164,  0.0329, -0.0598,  0.1106,  0.2095, -0.0724,  0.4145,\n",
       "           0.0777],\n",
       "         [-0.0660, -0.2606,  0.0911,  0.2285, -0.1754, -0.0952, -0.0940,\n",
       "          -0.1730,  0.0989,  0.0553,  0.2626, -0.0972, -0.1532, -0.0148,\n",
       "           0.0648,  0.1091, -0.1962, -0.0012, -0.3798, -0.0537,  0.2413,\n",
       "           0.0139, -0.3088,  0.1857, -0.1366, -0.1577,  0.0605, -0.0301,\n",
       "          -0.1302, -0.2101,  0.0904, -0.1312,  0.1190,  0.0570,  0.0710,\n",
       "          -0.2052,  0.3093, -0.2043, -0.0011, -0.0867, -0.1316, -0.0897,\n",
       "          -0.1281,  0.2826,  0.3258,  0.0223, -0.1109, -0.0993, -0.0540,\n",
       "          -0.3140],\n",
       "         [-0.1035, -0.0840,  0.0717, -0.0246,  0.3094, -0.1727, -0.1449,\n",
       "           0.2704,  0.0411, -0.1512,  0.0989, -0.0388,  0.0058, -0.0281,\n",
       "           0.1199, -0.0412,  0.1287,  0.1066, -0.1965,  0.0317, -0.0237,\n",
       "          -0.2623,  0.0212,  0.0441, -0.2497, -0.0205,  0.0150,  0.0442,\n",
       "           0.0726, -0.3028, -0.1150, -0.1738,  0.0859, -0.1938, -0.0491,\n",
       "           0.4355, -0.1066, -0.2056,  0.0287,  0.0138,  0.1722,  0.0827,\n",
       "          -0.1134, -0.2350,  0.1292, -0.0137, -0.2702, -0.0173, -0.0602,\n",
       "           0.2224],\n",
       "         [-0.1785,  0.1946,  0.0866, -0.2149,  0.1608,  0.1506, -0.0064,\n",
       "           0.2107,  0.0537,  0.1907, -0.2830, -0.1934, -0.1706, -0.1316,\n",
       "          -0.1022, -0.0952, -0.0545,  0.0303,  0.0354,  0.1357,  0.2469,\n",
       "           0.0813,  0.3298,  0.1718, -0.1947,  0.2007, -0.0027, -0.0708,\n",
       "          -0.0492,  0.2287, -0.0988, -0.0541,  0.2290, -0.0469,  0.0422,\n",
       "           0.0253,  0.0668,  0.2390,  0.1179,  0.0368, -0.3182, -0.2447,\n",
       "           0.0894, -0.0008, -0.0593,  0.3672,  0.1795,  0.2323, -0.1622,\n",
       "          -0.1370],\n",
       "         [ 0.0161, -0.1741, -0.0102, -0.1406, -0.0763,  0.2946, -0.0423,\n",
       "          -0.0006, -0.1902,  0.0477,  0.1458,  0.1483,  0.2761,  0.2190,\n",
       "          -0.0059, -0.3664,  0.1707, -0.2007,  0.0510, -0.2431,  0.0004,\n",
       "           0.1180, -0.1216, -0.2438, -0.0632,  0.0538, -0.2090, -0.0524,\n",
       "           0.0753, -0.0131, -0.0253, -0.2602,  0.1695, -0.0037,  0.1120,\n",
       "           0.3437, -0.0422, -0.0432, -0.3905, -0.0615,  0.1147, -0.0862,\n",
       "           0.1956, -0.1193, -0.1443, -0.0002, -0.2772,  0.0416, -0.0695,\n",
       "          -0.0671],\n",
       "         [-0.0122, -0.0222,  0.0278,  0.1290,  0.1060,  0.1668,  0.0568,\n",
       "          -0.2617,  0.0356, -0.1534,  0.2541, -0.0715, -0.2053,  0.1388,\n",
       "          -0.0709, -0.1966, -0.2282,  0.1158, -0.1437, -0.0644, -0.1802,\n",
       "           0.0395, -0.1527,  0.0653, -0.0408,  0.0139,  0.1085,  0.0939,\n",
       "           0.0074,  0.0372,  0.0685, -0.1992, -0.0584,  0.3325,  0.1555,\n",
       "           0.0175,  0.3773,  0.1068,  0.1237,  0.1708, -0.0265, -0.2992,\n",
       "          -0.1153, -0.0345,  0.1274,  0.0960, -0.0096,  0.0686, -0.1161,\n",
       "          -0.1043],\n",
       "         [-0.1207, -0.0658, -0.0217, -0.1594,  0.0185, -0.2379, -0.1980,\n",
       "           0.4249,  0.0815,  0.0614,  0.1466,  0.0787,  0.1027, -0.0137,\n",
       "          -0.2815, -0.0070, -0.3771, -0.0308, -0.2191,  0.1965, -0.1577,\n",
       "           0.0258,  0.1690,  0.3319,  0.0434, -0.1511, -0.1447, -0.0669,\n",
       "           0.1501,  0.0253,  0.0348, -0.0963, -0.1959, -0.0431,  0.0040,\n",
       "          -0.0798, -0.1613, -0.1340,  0.1105,  0.1484,  0.0178,  0.1785,\n",
       "           0.2317, -0.0500,  0.0057, -0.2661, -0.2405, -0.2786,  0.0450,\n",
       "           0.1178],\n",
       "         [-0.0136,  0.2397, -0.0581,  0.0352, -0.0665,  0.0420, -0.0103,\n",
       "           0.1187, -0.0383, -0.0013,  0.1156,  0.0113,  0.0599, -0.0397,\n",
       "          -0.1347,  0.0414, -0.1788, -0.1127,  0.1992, -0.0239, -0.1392,\n",
       "          -0.1113,  0.0771, -0.0013, -0.0898,  0.1526, -0.0133,  0.0309,\n",
       "           0.0393,  0.0747, -0.2200,  0.0758, -0.1924, -0.1392, -0.1067,\n",
       "           0.0349, -0.0720,  0.3592,  0.1813, -0.0988, -0.3170, -0.4183,\n",
       "           0.2536,  0.0754,  0.2432, -0.0196, -0.0146,  0.0542,  0.0714,\n",
       "          -0.0838],\n",
       "         [ 0.0338,  0.1320,  0.1348, -0.2810, -0.0721,  0.2201, -0.1056,\n",
       "          -0.0576,  0.0235, -0.1562,  0.0679,  0.2406, -0.1515, -0.1640,\n",
       "          -0.0319,  0.0020, -0.2115, -0.2752, -0.1452, -0.1076, -0.0285,\n",
       "          -0.0790,  0.0955,  0.1010,  0.3849, -0.2936,  0.4155, -0.0553,\n",
       "           0.1713, -0.0176, -0.0278,  0.0366, -0.2654, -0.3940, -0.1068,\n",
       "           0.0931,  0.0821, -0.0205, -0.0376,  0.0715, -0.0237,  0.0518,\n",
       "          -0.1486,  0.2386, -0.1949, -0.0954,  0.1679, -0.2504,  0.1244,\n",
       "           0.2429],\n",
       "         [ 0.2072, -0.1118, -0.1963, -0.1613, -0.0141, -0.0141,  0.1781,\n",
       "          -0.0762, -0.1844, -0.1015, -0.1276, -0.0717, -0.1566, -0.0364,\n",
       "           0.0006, -0.0808, -0.1189, -0.3346,  0.2293, -0.1316,  0.0651,\n",
       "           0.0037, -0.1626, -0.0418, -0.2395, -0.1256, -0.1327,  0.4608,\n",
       "           0.1202, -0.0426, -0.0883,  0.1180,  0.2114,  0.1570, -0.0972,\n",
       "          -0.1307,  0.2508, -0.0015, -0.1922,  0.1848, -0.2570, -0.1588,\n",
       "          -0.4923, -0.2961, -0.1091, -0.1652, -0.1647, -0.0190,  0.2436,\n",
       "          -0.3377],\n",
       "         [ 0.2813, -0.3283,  0.1949, -0.1384, -0.1299,  0.1466,  0.0348,\n",
       "           0.1978, -0.1050, -0.3435,  0.0139,  0.0079,  0.0090,  0.0593,\n",
       "           0.0191,  0.1475, -0.2334,  0.2984, -0.0968,  0.2759,  0.1365,\n",
       "          -0.0533,  0.1841, -0.0898, -0.1184,  0.1901,  0.1582, -0.0303,\n",
       "          -0.2825, -0.1690, -0.0100, -0.1569, -0.1328, -0.1782,  0.1109,\n",
       "           0.1637, -0.1125, -0.3398, -0.1127, -0.2955,  0.3329, -0.0213,\n",
       "           0.1397,  0.1298,  0.2071,  0.1326,  0.1030, -0.0985,  0.3187,\n",
       "          -0.0262],\n",
       "         [ 0.3038, -0.4026, -0.0614, -0.0675, -0.0414,  0.0624,  0.0133,\n",
       "          -0.0749,  0.2061,  0.1189,  0.1481, -0.2210,  0.2007,  0.1392,\n",
       "          -0.1096,  0.0911,  0.0091,  0.0840, -0.1398,  0.0607, -0.1349,\n",
       "          -0.1712, -0.3935, -0.1275, -0.0052,  0.1389, -0.1199, -0.0463,\n",
       "           0.1496, -0.2432, -0.1034,  0.2549,  0.2128,  0.0989, -0.1442,\n",
       "           0.1966,  0.0560,  0.2529,  0.2468,  0.0008,  0.3270, -0.1292,\n",
       "          -0.2783,  0.1652,  0.1587,  0.2170,  0.0473,  0.0750, -0.2006,\n",
       "           0.0345],\n",
       "         [-0.0167,  0.0048,  0.0758, -0.2546, -0.1129,  0.2501,  0.2560,\n",
       "           0.0527,  0.1633, -0.1031,  0.0768, -0.1766,  0.1912, -0.1540,\n",
       "           0.1943, -0.0912,  0.0114, -0.2477, -0.2128,  0.1349,  0.3348,\n",
       "          -0.0857,  0.0164, -0.0829,  0.0550, -0.1398, -0.2266,  0.1769,\n",
       "          -0.0997,  0.2877, -0.0063, -0.0639,  0.0386,  0.0819, -0.0753,\n",
       "           0.1753, -0.1770,  0.1164,  0.2518, -0.0601, -0.1839, -0.0324,\n",
       "           0.0658,  0.3281,  0.1224, -0.1826,  0.2095,  0.1643,  0.2557,\n",
       "           0.0089],\n",
       "         [-0.1334, -0.1577, -0.0595,  0.0103, -0.0445, -0.0028,  0.1606,\n",
       "          -0.1784,  0.2869, -0.0710,  0.0069, -0.0012, -0.1349,  0.0606,\n",
       "           0.0842, -0.1347,  0.0900,  0.0594,  0.1373,  0.1683, -0.1826,\n",
       "           0.1121,  0.0821, -0.0122, -0.1131,  0.0081, -0.0017,  0.1396,\n",
       "           0.1149,  0.1217, -0.0700,  0.0863,  0.0595, -0.1041, -0.0551,\n",
       "           0.0043,  0.0115,  0.0425,  0.0027,  0.0145, -0.0571,  0.1611,\n",
       "          -0.2949,  0.1245, -0.1261, -0.1245, -0.0971, -0.2188, -0.0269,\n",
       "          -0.1551]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Инициализация весов\n",
    "stds = [(2/(50+20+1))**(1/2), (2/(20+10+1))**(1/2), (32/(10+1+1))**(1/2)]\n",
    "null_weigth = []\n",
    "stds.reverse()\n",
    "def get_weights(layer):\n",
    "    if (type(layer) == nn.Linear):\n",
    "        null_weigth.append(torch.randn(layer.weight.data.shape)*stds.pop())\n",
    "net.apply(get_weights)\n",
    "null_weigth.reverse()\n",
    "null_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_null_weigth = null_weigth.copy()\n",
    "def init_weigths(layer):\n",
    "    if(type(layer) == nn.Linear):\n",
    "        layer.weight.data = tmp_null_weigth.pop()\n",
    "net.apply(init_weigths)\n",
    "net.lin1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(size_average=True)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c6fd5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "feature_index\n",
    "learn_epoch_loss = []\n",
    "valid_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "for epoch in range(10**4):#10**5:\n",
    "    loss_acc = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    for learn_data in learn_dataloader:\n",
    "        features_learn, labels_learn = learn_data[:, feature_index], learn_data[:, label_indx]\n",
    "        features_learn, labels_learn  = autograd.Variable((features_learn).float()).unsqueeze(1), autograd.Variable(labels_learn.float()).unsqueeze(1)\n",
    "        outputs_learn = net(features_learn)\n",
    "        loss_learn = criterion(outputs_learn, labels_learn)\n",
    "        loss_learn.backward()\n",
    "        optimizer.step()\n",
    "        loss_acc += float(loss_learn.data)\n",
    "    learn_epoch_loss.append(loss_acc/len(learn_dataloader))\n",
    "    \n",
    "    for valid_data in valid_dataloader:\n",
    "        features_valid, labels_valid = valid_data[:, feature_index], valid_data[:, label_indx]\n",
    "        features_valid, labels_valid  = autograd.Variable((features_valid).float()).unsqueeze(1), autograd.Variable(labels_valid.float()).unsqueeze(1)\n",
    "        outputs_valid = net(features_valid)\n",
    "        loss_valid = criterion(outputs_valid, labels_valid)\n",
    "        valid_epoch_loss.append(float(loss_valid.data))\n",
    "        \n",
    "    for test_data in test_dataloader:\n",
    "        features_test, labels_test = test_data[:, feature_index], test_data[:, label_indx]\n",
    "        features_test, labels_test  = autograd.Variable((features_test).float()).unsqueeze(1), autograd.Variable(labels_test.float()).unsqueeze(1)\n",
    "        outputs_test = net(features_test)\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "        test_epoch_loss.append(float(loss_test.data))\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        plt.grid(True)\n",
    "        plt.plot(learn_epoch_loss, color='r') \n",
    "        plt.plot(valid_epoch_loss, color='b') \n",
    "        plt.plot(test_epoch_loss, color='g') \n",
    "\n",
    "        display.clear_output(wait=True) \n",
    "        display.display(plt.gcf()) \n",
    "\n",
    "        print(epoch, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"learn loss: \", learn_epoch_loss[len(learn_epoch_loss)-1])\n",
    "print(\"test loss: \", test_epoch_loss[len(test_epoch_loss)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
